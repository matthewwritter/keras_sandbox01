{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mritter/anaconda3/envs/tf_gpu_test04/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-209078942ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# confirm TensorFlow sees the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m'GPU'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# confirm Keras sees the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# IF IT DOES NOT WORK, MAY NEED TO RESTART COMPUTER\n",
    "\n",
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "assert len(backend.tensorflow_backend._get_available_gpus()) > 0\n",
    "\n",
    "# confirm PyTorch sees the GPU\n",
    "from torch import cuda\n",
    "assert cuda.is_available()\n",
    "assert cuda.device_count() > 0\n",
    "print(cuda.get_device_name(cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "# https://files.pushshift.io/hackernews/ (first file)\n",
    "# https://files.pushshift.io/hackernews/HNI_2006-10.bz2\n",
    "# Manifest: https://files.pushshift.io/hackernews/HNI_total_items_by_month.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get  # to make GET request\n",
    "\n",
    "\n",
    "def download(url, file_name):\n",
    "    # open in binary mode\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        # get request\n",
    "        response = get(url)\n",
    "        # write to file\n",
    "        file.write(response.content)\n",
    "\n",
    "download('https://files.pushshift.io/hackernews/HNI_total_items_by_month.txt', 'data/manifest.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        61 HNI_2006-10\r\n",
      "         1 HNI_2006-12\r\n",
      "      1549 HNI_2007-02\r\n",
      "      6305 HNI_2007-03\r\n",
      "     10335 HNI_2007-04\r\n",
      "      7516 HNI_2007-05\r\n",
      "      6036 HNI_2007-06\r\n",
      "      6410 HNI_2007-07\r\n",
      "     10841 HNI_2007-08\r\n",
      "     12371 HNI_2007-09\r\n"
     ]
    }
   ],
   "source": [
    "! head data/manifest.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134    [209738, HNI_2018-02]\n",
       "135    [237342, HNI_2018-03]\n",
       "136    [237609, HNI_2018-04]\n",
       "137    [237646, HNI_2018-05]\n",
       "138        [17172781, total]\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with open('data/manifest.txt', 'r') as f:\n",
    "    manifest = pd.Series(f.read().split('\\n')).map(str.split)\n",
    "    manifest = manifest[manifest.map(len) > 0].reset_index(drop=True)\n",
    "manifest.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os.path\n",
    "\n",
    "# url_format = 'https://files.pushshift.io/hackernews/{}.bz2'\n",
    "# file_format = 'data/{}.bz2'\n",
    "# for size, filename in manifest:\n",
    "#     if os.path.isfile(file_format.format(filename)): continue \n",
    "#     download(url_format.format(filename), file_format.format(filename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/HNI_2011-10.bz2  data/HNI_2011-11.bz2  data/HNI_2011-12.bz2\r\n"
     ]
    }
   ],
   "source": [
    "! ls data/*2011-1*bz2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import re\n",
    "for i in range(len(bjc)):\n",
    "    bjc[i]['text'] = bjc[i]['text'].lower()\n",
    "    bjc[i]['text'] = re.sub('http.*\\w',' <LINK> ',bjc[i]['text'])\n",
    "    bjc[i]['text'] = re.sub('\\n|\\r|\"|\\'|\\?|&#34;|\\.|\\,','',bjc[i]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import ascii_letters\n",
    "ascii_letters.index('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "from dask.distributed import Client, progress\n",
    "import json, re\n",
    "client = Client(n_workers=8, threads_per_worker=2, memory_limit='6GB')\n",
    "client\n",
    "\n",
    "def comment_filter(record):\n",
    "    return (record['type'] == 'comment' \n",
    "            and record.get('deleted', None) == None\n",
    "            and record.get('text', None) != None)\n",
    "\n",
    "def text_transformation(record):\n",
    "    text = record['text'].lower()\n",
    "    text = re.sub('http.*\\w',' <LINK> ',text)\n",
    "    un = record['by'].lower()\n",
    "    return (un, text)\n",
    "\n",
    "b = db.read_text('data/*bz2').map(json.loads).filter(comment_filter)\\\n",
    "      .map(text_transformation)\n",
    "\n",
    "# temp = b.to_dataframe()\n",
    "# temp.index = ['un', 'text']\n",
    "# temp2 = temp.tail()\n",
    "# temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "the article says that because the mentors found the project work acceptable, then lines of code becomes a good measure of productivity, even though it generally wouldn't be. but i think it's still a bad measure of productivity.<p>in fact, i think the lesser amount of code for the same size project is more productive. i'd prefer the programmer who can meet the project goals in 4,000 lines of code over the one who does it in 20,000 lines. given those two numbers, i can't help but feel that the 20,000 lines is spaghetti code. (i realize this in my own prejudice and it may not be the case.)<p>as antoine de saint exupery says: \"perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.\"<p>going for perfection, in most cases, is probably not the most productive use of time. but i think this quote is still generally true for programming."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "with all due respect andrew why dont you share your technical analysis of what exactly i am saying that is wrong here. btw, have you ever actually <i>worked</i> on any database scaling problems? just checking."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "give me a break. there are very few organizations less well equipped to respond to computer attacks than us law enforcement. it takes <i>years</i> to convict on computer crime cases, and almost every one of them is front page news in the trade press. you know how many we've had in the past decade?<p>trivia question: which law enforcement agency was primarily responsible for responding to computer incidents throughout the 80s and 90s?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "agile album development."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "you're absolutely right, and there is certainly a lot of money to be made. i don't know what the answer is; but i know i personally would have to think twice before putting all my eggs in the facebook or twitter basket."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "another reason not to eat ground-anything. one, it's harder to keep ground meat clean; you can't clean off the e-coli once it's been mixed in.<p>now we won't be able to tell whether we're eating real or synthesized sausage.<p>i would be reluctant to eat synthesized meat because we probably don't understand (or manufacturers will ignore) the entire relationship between a) the result of the complex process of growing meat on an active bone that's running around, and b) how our bodies evolved to process and benefit from <i>exactly</i> that configuration of protein, nutrients and composition."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "what would be nice, is if the credit card companies could save your \"default\" shipping preferences.  then, unless you wanted to ship somewhere else, online checkout would only need to ask for your cc number... almost as easy as a retail transaction."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i hope so (although i find the whole thing a bit odd - why is it being merged now, if the work was mainly in fixing llvm; why not spend another year and hit the numbers?  pypy has been steadily improving, and while people have said there's room for both, this smells a bit political...)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "where i grew up i would say building your own home is almost as popular as buying one. but i wouldn't say the land is \"nice.\" you can even do this in places close to silicon valley, such as the santa cruz mountains. although, there can be a lot of restrictions on the land use due to environmental and other zoning regulations."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&#62; it seems to me that the \"relax labs\" ought to be more corporate or at least corporate-sponsored<p>oh yes, i completely agree on that. i've worked at one of these places, and what they made was exactly the definition of \"cool gadgets\". to my eyes, it wasn't research, it was pure development. stuff like this should be funded by a company to build a product, not by universities.<p>i can't go too much in the details, but one of the things they built was a blogging robot. it has a pda and blogs your location for some reason..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "they do drive on the left..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "well, wait.  i hate the nytimes and generally distrust them as well, and what they've written is slightly inaccurate.  but at the same time, the bloomberg article states the neutral policy doesn't apply to mobile - verizon still gets to throttle there.  the number of people who access the internet only by mobile phone is increasing, and as rumors are leaking about a 1.5ghz phone, and the ipad is getting more and more popular, i can't help but think mobile will some day be the biggest if not only thing actually accessing the internet."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "would you mind giving more details on this? i don't understand how it would be possible for a human to do this with n &#62; 1kish, and even then i would imagine it being horribly slow."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i don't see anything wrong with apple maintaining this much cash, it has serious strategic (albeit unquantifiable) value. who could outbid them if they saw a serious opportunity?<p>one of the best ways to maintain a strong lead is to have the cash necessary to dispose of the competition at will.<p>what's the alternative, bankrolling dipshit* startups as an expensive way of handling recruiting ala google?<p>*i jest, don't freak out and get into yet another argument with me, i beg you."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "having used outlook with exchange myself, i agree that it has some wonderful functionality.  but if outlook will do something as sloppy as sending a batch of read receipts when it makes absolutely no sense to do so, that doesn't instill a lot of confidence in the software in general."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "well, he did say \"weekend project\" ;)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "twitter's app completely breaks two of the three window controls.<p>close --&#62; actually just hides the app.\n",
       "expand --&#62; does literally nothing. seriously."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "google makes money out of being the #1 search engine. concurrence from others is one thing. concurrence from someone stealing your source code (open source or not) is a whole different story. that should be reason enough, in my humble opinion."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<i>70% of something is better than 100% of nothing.</i><p>100% of nothing is preferable to 70% of \"something\", if it costs you 90% of \"something\" to deliver the service, and \"something\" is already the maximum price the market will bear (and apple will not allow you to increase the \"something\" only on ios to compensate for their demands anyway)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\"wait, just being able to ask the question? there isn't even a dependance on the answer?\"<p>you appear to have skipped over the word \"meaningfully\" in warrenwilkinson's post, or perhaps he edited it in, but either way, it addresses your concern.<p>(to your later point i'd observe that rights are generally considered symmetrical; in a society where you have \"the right to liberty\" your example falls through because a's right is being violated for your example, and your argument seems to fundamentally require asymmetry for it to make any sense.)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "tahoe-lafs seems to fit the bill, except i don't know about  #3. from what i understand it's rather stronger on #2, though."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<i>i'm constrained by my ability to learn and that is pretty much it.</i><p>well, i think it is more subtle than that. you are relying on certain externalities - for example, you can't build a chip fab without spending an enormous amount of money, and you need all that power so you can work in python and not asm, you can't lay ubiquitous bandwidth without spending an enormous amount of money, etc.<p>what you are doing is equivalent to your friend creating whatever she can imagine in microstation (or whatever cad architects use these days). it's just that she seems to be more aware of the commercial aspects of actually making it happen than you are."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "dennis prager, a nationally syndicated talk show host, has requested such an app.  he said he'd give an on-air interview to the person who makes it.<p><a href=\" <LINK> >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "amen.  my math instructors were great---i can't say the same for the methods they had to use."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "how about we've progressed to the state where html is the bytecode you don't want to see anyway, and designers can use modern tools to manipulate it? if the generated markup works, cross-browser and cross-platform (i don't know to what extent it does, but let's assume so), then what's the problem?<p>for many purposes, optimizing the html nerd out of the process is a much bigger win than a 20k download (don't forget gzip) is a loss.<p>i know this is going to get me downvotes, but i think the dogmatic \"html shall be written by hand!!1\" attitude all over this thread is just people clinging to the past."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "no, it appears as if it was just altered in the ways that would help their case, <i>in this instance</i>.  with the tablet filing, the aspect ratio appears to be altered - and perhaps not coincidentally, altering the aspect ratio in that filing was more beneficial.<p>the end result appears to be, in both the tablet and phone filings, that the alleged image manipulation produced something that appeared more similar to apple's products.  that the image manipulation is different (aspect ratio adjustment, vs resizing) seems to be <i>more</i> damning than if the same adjustment was made across the board (i.e. it looks less likely to be accidental)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "this essay is even more relevant now than it was in 1975, and the same reasoning can (and should) be applied outside of science fiction books."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&#62; why is that always the first solution we turn to?<p>first, i'm sorry for your loss. i did want to point out that there's no reason to believe that this is an either-or situation. clearly research can progress in all directions now in a more focused manner: further understanding the cause of the mechanism identified, as well as attacking it directly."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "entering the airbnb for dogs market might face competition from entrenched players, as a whois search shows that airbnb ceo brian chesky already owns dogbnb.com"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "of course, a bunch of this work is sabotaged by stupid default `ldflags` you get if you use `pkg-config` and some package (like `gmodule`) throws random stuff in there like `-wl,--export-dynamic` which is just totally unnecessary for at least 99% of executables which only ever used `gmodule` indirectly in the first place..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "an interesting article.<p>some of those things are mentioned in the classic hacker book \"the newtonian casino\"<p>(<a href=\" <LINK> >)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "what we can get out of this is post is that there is a lack of common protocol between the existing contributors and new ones who want to jump in. if todo is not the right fit, then something like a fixme or testme should help the new developer get started quickly. if a project follows this protocol, just add notes in the contribute section of the readme; something like: \"new contributors can get started with looking for fixme in the code base\"."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "you can in the uk."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "it works for me too.  received the email in under 5 seconds.\n",
       "maybe there's a dns problem somewhere.  in any case the title seems awfully presumptive.  the likelihood of the bug being on hn's end seems unlikely."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "nah, you're already screwed. if you get to the point of the pop-up it is already too late."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i've gone seven years now without college, and i've found that my previously brazen attitude about not needing college has been tempered with a deeper understanding about what college will be able to give me, should i ever attend.  of course, the needs might well be met by the oncoming wave of moocs, but the idea that knowing what one <i>wants</i> out of something (in this case, college) before executing on it is a force multiplier to its effectiveness applies to a great many other things.  why not here?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "decent list of observations on startup landscape. if you are interested and haven't had an opportunity to read, mary meeker's internet trends (<a href=\" <LINK> ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "so that would fall under the <i>appropriate compensation / benefits</i> category then. i don't think the op is saying money isn't a factor, just that it is not the <i>only</i> factor all things being equal.<p>i have taken jobs before where i got paid less because i would learn much more in the new job, inevitably allowing me to earn more money in the longer term. had i stayed at the old job i would have found it extremely difficult to find a job now with very outdated skillset."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "perhaps the difficulties tim is talking about are really renderer shortcomings and not the format itself, which i had assumed was a lot more restrictive than html."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "reading the comments here, i wonder if most people read the article all the way down to the paragraph that begins: <i>\"frampton’s long-held defense\"</i>? i don't want to spoil it, but would highly recommend reading the entire article before forming any conclusions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wouldn't the opposite be just as bewildering then? there really is no difference between buying a hermes dress and buying dickies overalls, right? each item makes a statement and each person is well aware of the statement it makes. both can be bought for practical reasons. both make comments on social placement. both help people identify themselves. both help find/identify suitable mates.<p>i too find it so hard to believe people spend so much on apparel, but that thought is no different than people finding it odd that i spend so little. of course, some items are easy to liquidate and others are not."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "hmm, i imagine that this is a complete scam. or am i too skeptic? where is the proof that this is 100% legit and not some mumbo-jumbo psyche stuff?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "perhaps you know how things are going on under the hood, but i have worked with many ios developers, and the ones who love interface builder have been clueless. they don't understand the actual view hierarchy, autoresizing masks, and god forbid you need an ib-guy to dabble in coregraphics drawing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "thanks for this. i'll take a look at those areas.\n",
       "though i'm wanting more functionalities, will it be okay if i gather likes for the facebook page even though the functionalities i wanted are not yet implemented? (e.g. first impression of the site's current functionalities can make a visitor like/dislike the site)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "see also <a href=\" <LINK> ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "he&#x27;s a fat boy. walks really slow :) i expected  webdirectx!"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i don&#x27;t remember what rtg stands for, but i&#x27;m pretty sure they mean adding radioactive bits to the battery."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\" <LINK> >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "post-secondary education is pretty much universally accepted as a good thing, but it doesn&#x27;t pan out for everyone. this might be their way of both accepting that not everyone worthwhile gets their degree, but at the same time they don&#x27;t want to motivate people not to go at all."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "boulder has been lagging somewhat, but starting to see averages approaching that range (the deleted comment mentioned $120k-ish). i also wish there was a way to measure the quality of pub&#x2f;cafe conversation, because i feel like that has improved dramatically as of late."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&gt; if you&#x27;re not ready to pay, then why the hell are you trying my service?<p>to find out if i like your service enough to pay for it?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "it could easily mean they&#x27;re no longer letting them work on their projects on the clock, though."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "well that was a pretty mean thing to say. not everything needs to be a cure for cancer or fix peak oil. we need some room for leisure. if the author had fun making something that provides him with some cash, i don&#x27;t see what the harm is. that just leaves more easy &quot;real&quot; problems for people like you to go out and solve."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<i>is our industry doing the equivalent of offering free rides to hopeful software developers, calling them pilots, and throwing them by the thousands into airplanes just to watch them crash and burn?</i><p>with some exceptions, it&#x27;s less dangerous when a novice programmer writes ugly code than when a pilot crashes a plane.<p>so we shouldn&#x27;t require as much caution around letting people program as we do in letting them fly an airplane."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "no, he increased his chance of success by working hard. luck != success."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ah yes. in both new york and san francisco there are fun and exciting zero-sum dominance games, <i>combined with</i> the overhanging threat that some communist like bill de blasio might get elected and decide to take away your future rental income by tightening the rent control regime. and people wonder why the rent is too damn high.<p>not sure which city has it worse today. of course, in new york in the sixties and seventies, over a third of the apartment buildings in harlem were simply abandoned and left to rot, and the bronx was burned; i&#x27;m not aware of similar destructiveness in san francisco (notwithstanding even the japanese internment which replaced japantown with the abominable public housing in the modern fillmore and western addition)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "three years ago i just went for bose qc-15s (in-canal earbuds weren&#x27;t an option for me, but might be for you, to change-up &#x27;phones throughout the day. most are isolating, some are noise-cancelling).<p>aside from the noise-canceling, the qc-15 feature i like best after 3 years of semi-daily use is that the cable disconnects smoothly from the headset when stressed, like when you suddenly stand up while forgetting to take off the &#x27;phones. i bought a spare cable, anticipating breakage, but i&#x27;ve never needed it.<p>these are personal, &quot;pro-sumer&quot; headphones, which are definitely not built to take years of daily recording studio rough-and-tumble step-on, sit-on, throw-around abuse. i&#x27;ve never sat on or stepped on my qc-15s, so i don&#x27;t know how they&#x27;d be affected.<p>these headphones offer pretty good battery life (i get 40 hours, because i don&#x27;t crank them loud) and soft circumaural earpads. but even with the light earpad pressure on my big head, i &quot;run hot&quot;, so the heat and sweat build-up sometimes bothers me. this is true of all &quot;sealing&quot; headphones. i got some relief with my earpad covers made of stretchy t-shirt fabric. eyeglass wearers will feel pressure on the frames; i don&#x27;t know any way around it.<p>sound quality is fine for me with good bass and clarity; the sound stage is so quiet it&#x27;s initially a bit spooky. they&#x27;re quiet enough and sensitive enough to reveal sonic source faults like my laptop&#x27;s hisses and crosstalk. i don&#x27;t know how durable they are against overload: i suspect fairly robust, because the speakers are driven by the 1.5v-powered internal amplifier, not the source (mixer, guitar amp, etc). but i also don&#x27;t know how protected they are against input signal level over their maximum rated 9 vrms (<a href=\" <LINK> ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "for all intents and purposes an email address is a unique identifier. this is the status quo that the rest of the internet maintains.<p>i&#x27;ve got two amazon accounts under the same email address that happen to have two different passwords. my order history is more or less split evenly between the two since either password mnemonic works. it has caused such frustration that i even stopped buying digital goods on their platform and switched to using google play. (it&#x27;s not the only reason for my decision, but it certainly factored in.)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "there is no limitation except driven by architecture.<p>usually there is a limit on how many you can do without putting a conference server, 5 is quite okay for hd video on a laptop. typically in these cases (mesh scenarios) the cpu&#x2f;memory is a limitation than capacity. upto 10, if everyone is doing sd video. so services pick a number 7 or 8 to limit the participants in a video some doing hd, some doing sd. this number is smaller if you pick ipad&#x2f;tablets and higher if you are on a macpro or something with multiple gpus (possibly in these cases limited by capacity).<p>if the service builds a mcu (or conference bridge) those typically do not have such limitations, it then depends on how you multiplex the streams, mix them or selectively forward them, if the server is just forwarding packets, or decrypting them and re-encrypting them because it is transcoding or re-writing rtp headers, etc."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "social engineering applies to pretty much everything. it has nothing to do with bitcoin (or whatever else a social engineer wants from you) and everything with your own lack of due diligence and gullibility."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "your link to the herald tribune and mercola both recommend dha (and omega-3). it is seriously one of the greatest things you can take, hands down. nordic natural is an expensive brand, and buying at whole foods is even more expensive (try amazon, and a cheaper, but quality brand is carlson&#x27;s). it is hard to tell sometimes when you go off a supplement the true effects because your high dha levels can take a while to be used up, and even then the body has processes to try and scavenge or breakdown molecules in other areas to make up for it. it is much more efficient and beneficial to provide the needed stuff in a useable form."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "bruce schneier does have vast expertise when it comes to security&#x2f;encryption and the fact that he is formulating his conclusions in a way that they can be consumed by the general public, is something that is commendable and makes him way more dangerous for the nsa. which is one of the reaseons why he gets attacked for it, i guess."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wikimedia is the parent project of wikipedia, wiktionary, wikiquote, wikinews, and so on.<p>the wikimedia wiki is used for documentation and discussion on the topic of running a wiki, and on specifically running mediawiki (the underlying software that powers these sites).<p>since this is an article about a topic relevant to running wikis, it&#x27;s on the meta wiki. it is unlikely to be notable enough to meet the criteria for being included in wikipedia; in order to avoid everyone creating their own personal wikipedia page or a wikipedia page for their high school band or the like, which can be very hard to ensure is high quality and accurate, wikipedia has notability and verifiability requirements. something must be notable enough to have been published by several existing reputable sources in order to meet this guideline.<p>it&#x27;s fairly likely that cunningham&#x27;s law does not meet those criteria. but the wikimedia meta-wiki has less formal requirements, and its topic is explicitly discussion about running wikis, so this winds up there.<p>if you click on the logo, you can see this described straight from the source: <a href=\" <LINK> ;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i read the linked webpage, and i have had none of the issues he seems to think occur with git pull --rebase. i believe he uses git differently than i, and many other people, do.<p>whenever i&#x27;m about to begin work i create a new branch. i git pull --rebase that branch with the upstream branch i am going to merge with frequently while i work. i&#x27;ve never had any unexpected behaviour."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "per month? that&#x27;s $120&#x2f;year, or $360 for 3 years.<p>i think you can buy a couple of 3 tb hard drives for that."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "my opinion is irrelevant. and if your point had any validity, it would transfer right across.<p>you&#x27;re changing the topic - you know i&#x27;m right. take it to heart, please. these things are important."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "the video seems to be down now?  anyone have a mirror?<p>edit: nevermind, i clicked the download link.  but i&#x27;m still wondering why the video&#x27;s unplayable on the site."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "this is one of those stories where i wish the title conveyed more information.  at first i thought it was going to be about light pollution and how we can&#x27;t see most of the stars anymore."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "just because it isn&#x27;t your personal preference doesn&#x27;t mean no one should think about cyclists. there are many pro- and con-cyclist arguments, all of which are irrelevant to this discussion."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "nice reading this was"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i think the link to the original is sufficient alas <a href=\" <LINK> >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "how does one prove this &quot;mediocrity principle&quot;? &quot;specialness&quot; is in the realm of philosophy and from that perspective, this principle just comes across as a mellow form of nihilism. telling students to filter all of science through the &quot;we&#x27;re not special&quot; lens just biases them so that if there actually is something special, they will be blind to it. \n",
       "might i suggest as an alternative the &quot;keep an open mind principle&quot;?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "its something they know about. the current workaround is multiple masters, which isn&#x27;t entirely practical"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i wonder how this affects the fish&#x27;s slime coating, which is important to preserve. it seems like this would be rubbed off on the material as the fish is propelled along the tube, no?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "it&#x27;s the history eraser button you fool!<p>i just had to push it - so jolly and candy like.<p>it is kind of expensive so i am looking for $50,000,000.00 in vc to develop an online version. here&#x27;s the first prototype:<p><pre><code>    &lt;button&gt;button&lt;&#x2f;button&gt;</code></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<i>“this is absolute madness, ambassador,” president merkin muffley says in the film, after being told about the soviets’ automated retaliatory system. “why should you build such a thing?”</i><p>in the case of the russian &quot;dead hand&quot;, one of the stated purposes was to reduce the potential for nuclear war, by allowing the command-and-control structure to delay the decision about retaliation until it is clear that a possible attack is, in fact, a real attack.<p>if you think &quot;i have 30 seconds to decide whether to launch a retaliatory strike&quot;, you&#x27;re far more likely to make a bad decision than if you think &quot;i don&#x27;t need to do anything, because if the blips on our radar are icbms then a retaliatory strike will happen after i&#x27;m dead&quot;."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ca also offer more expensive tiers of certificates, that include ev, or a warranty for commercial transactions.<p>i&#x27;ve never used those, and i don&#x27;t know how relevant these are for companies, though."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "it&#x27;s probably the same material they use to make park slides.  if the sun&#x27;s out, they are usually too hot for the kids to slide on..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "what do you think is wrong with ayn rand? i&#x27;m an extremely intelligent person, i&#x27;ve studied her work for many years, and i think she&#x27;s right. and there are a lot of people like me, and the number is increasing. (i&#x27;m not making an argument from authority here; i.e., that is not an argument that she is right.)<p>edit: and i take it for granted that lying is not generally acceptable. i didn&#x27;t mean to imply that it&#x27;s worse to lie about ayn rand than something else.<p>another edit: and i don&#x27;t mean to goad you into discussing this. if you say you don&#x27;t want to get into a huge philosophical discussion, i&#x27;m not going to say &quot;see, you don&#x27;t have any argument&quot; or some crap like that."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "hrm... i got a few down votes for my guess (well, i started with &quot;i&#x27;d say that...&quot; but it was later qualified as a supposition.  i also wasn&#x27;t making a judgement call that it was bad - just observing that they made a big architectural change, and performance probably wasn&#x27;t the primary consideration for rev 1.  weird..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ms actually moved the gui stack into the kernel around nt 4. used to be (so legend has it) if the video driver crashed on earlier versions of nt, you could restart it, and the system didn&#x27;t go down. but, you know, performance!!1. win."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "with regards to disk space - compressed text logs are pretty common.  the frequency with which they are compressed is adjustable, and, gzcat is a pretty well known mechanism for opening them."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "furthermore, the idea of the &quot;one single algorithm&quot; followed by extinction that the parent poster proposes is overly simplistic.<p>assuming the sheer level of interconnectedness and computational ubiquity where every conceivable piece of matter used by humans out there has a bus or exports a remote api for most of these far-fetched agi apocalypse scenarios to work, it&#x27;s probably wiser to worry about crippling cyberwar way before agi is even a consideration."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "very interesting! the missing piece seems to be versioning on the libraries, for example:<p>lib:apache&#x2f;aurora&#x2f;0.5.x<p>without this, i can imagine a new version of aurora introducing a new required config field, the flabbergast library being quietly upgraded to handle this, and then users seeing inconsistent behaviours.<p>remember that config file formats are one of the least well-behaved pieces of a software&#x27;s public api (prone to breaking changes in even minor releases), so it seems sensible to build this in from the start."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i still remember when amazon ca accidentally had this on sale for a pittance, then axed all the orders when people tried to buy it. really should get a copy at some point."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "seems like lua would be a perfect target for ragel. do you know if anyone is working in this direction ?<p>how does it compare with lpeg[1] ? this is what i currently use for all my parsing needs.<p>[1] <a href=\" <LINK> >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "the internet is not a place apart from society. it exists within society. and society will exert the same amount of control over it as it asserts on other facets of life in order to meet social priorities."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ridiculously hostile response, especially considering the original fucking post is form someone who clearly doesn&#x27;t know about this stuff."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i have not reached for the inspect element faster than seeing this abomination. who thought that an all red webpage might be difficult on the eyes?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "actually the kickstarter did ship hence why i had my hands on one (well two actually) to do this hack. i backed the kickstarter back in may 2015.<p>the june2016 date is for orders placed on their store today which i think is the earliest they currently expect to have filled all the current pre-orders and later stage kickstarter backers. iirc they&#x27;re currently producing 5000 units a month."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "we had this in mass. it passed by a wide margin in every district. people understand that corporations != people. a corporation is a machine, a golem that we create to do our bidding. there&#x27;s no need to treat them as anything more than that."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "automatically indicting parents of abducted children follows as one consequence."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "a distinction in phrase only."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "it&#x27;s a little darkly funny how people react to perceived indignities in the sciences with the <i>exact same behavior pattern</i> they&#x27;re bemoaning.<p>the narrative of these people is that there are <i>bad people</i> out there doing <i>unreproducible work.</i> they know they&#x27;re bad, but they&#x27;re just motivated by grants, low p-values, etc, and eventually they just snap and do bad science all over the place. it&#x27;s an incentive problem.<p>so, to prove this, they... go get grants, do a meta-analysis with some nice statistics, and get subjected to the same incentive system. except this time, they don&#x27;t even have to do anything original. they just have to badly copy something else.<p>there&#x27;s <i>always</i> something like this in the article:<p>&gt;in his lab, baumeister told me, the letter e task would have been handled differently. first, he’d train his subjects to pick out all the words containing e, until that became an ingrained habit. only then would he add the second rule, about ignoring words with e’s and nearby vowels. that version of the task requires much more self-control, he says.<p>i really hate getting science news from sources like slate, because you have to decompile the journalese into what the scientist actually said, but the technical terms here are that baumeister had participants perform a fixed-target character recognition task. this is an incredibly old cognitive task that was used in some of the first cognitive psychology experiments like [<a href=\" <LINK> ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "did you miss the first sentence, the part about paying taxes?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "that caught my eye as well so i googled past surveys to see how the results have shifted.  what was more interesting to me is the 2016 distribution is very comparable to the 2013 distribution.  but then again this survey hasn&#x27;t been going on for that long. \n",
       "<a href=\" <LINK> >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "the difference is in the timing. prior to receiving an nsl, it&#x27;s legal for you to say you didn&#x27;t get one.<p>in the example of insider trading, it was never legal for you to give inside information. so stopping your haiku is legal, but the discussion when you agreed &quot;sell your stock when my haiku ends&quot; was not."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&gt;&gt;you don&#x27;t know how long you will live<p>going by the trends you will likely live long.<p>&gt;&gt;and what is your old days worth if you broken in your youth trying to be safe when you are 50?<p>far more worth than being 50, out of cash or very little of it, competing with a impossibly competitive new generation. living in perennial fear of layoffs, making ends meet and having a roof above your head. all the while watching your peers who made sound investments already retire and having a gala time now.<p>&gt;&gt;i&#x27;d rather work, as some do, 3-4 hours every single day for the rest of my life, than 12 hour days for 10 years and then compensate my lost youth, health and relationships with yachts or whatever money could buy.<p>retirement has rarely meant turning into a vegetable these days. retirement only means financial freedom to do what you want. imagine how valuable your relationships will be when you spend quality time with your friends and family, instead of running into old age expecting help from everyone starting from family, friends to government.<p>&gt;&gt;that is what socialism-&gt;communism was about in my country. we have to suffer just a little more and then we&#x27;ll get there. guess what. we never got there.<p>as a indian who lived through socialism i can tell scores of people &#x27;got there&#x27;."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "pump and dump couldn&#x27;t dump!"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "if it&#x27;s already serial, and only works with one backend (rather than being an arbitrary mirroring tool like wget), then the wayback server can easily &quot;express its preferences&quot; for rate-limiting by adding artificial delay to request-responses that pass the rate-limiting threshold. backpressure shouldn&#x27;t be the client&#x27;s responsibility.<p>(it only is traditionally, because so many sites do nothing to protect themselves from &quot;being too nice&quot;, so arbitrary-backend mirroring-client devs allow their users the option to ask for less than they want. this isn&#x27;t a sensible protocol design, on either side; it doesn&#x27;t optimize for, well, anything.)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "and every one of those things was targeting illegal brothels run by pimps in chicago.<p>if the facilities themselves were gov&#x27;t ran, with weekly medical checks and safety protocols, then i have a feeling things would be very different.<p>right now, with prostitution being illegal, it is abhorrent and disgusting and evil. i&#x27;m thinking of the similar comparisons with colorado and marijuana."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "mcdonnalds is paying even higher costs than that in other countries and hasn&#x27;t done it.<p>we have fully automated pizza making machines, but you still see plenty of people in pizza shops. the economics clearly don&#x27;t work out in favor of full automation at the moment."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "oh absolutely not<p>they taste <i>extremely</i> different<p>which doesn&#x27;t help because most places only serve diet coke (which i hate) instead of coke zero (which at least is available in most supermarkets)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "this blog post [1] and its predecessor explaining huffman codes [2] was a very helpful guide for me.<p>[1] <a href=\" <LINK> >\n",
       "[2] <a href=\" <LINK> >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "yeah."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\" <LINK> >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i learned it recently, the best tutorial on django is right in the docs.  the docs start you off with a tutorial for building a polling app that is really great for teaching the basics<p><a href=\" <LINK> ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "there are a few issues with this idea.<p>first, you say that it wouldn&#x27;t be that expensive at £185&#x2f;year, but that&#x27;s the price when you&#x27;re also offering rights to others in the union to live and work in your country and giving access to your market to the rest of the union&#x27;s goods.  the £185&#x2f;year would barely scratch the surface.<p>second, who would the cash come from and go to?  presumably, it would be from individual britons.  would it go to the rest of europe?  £185&#x2f;year would be very cheap to gain access to the right to live and work in europe.  in fact, countries do sell citizenships, but for a lot more than that.  i believe malta is the easiest way to buy yourself eu citizenship and requires a gift of €650,000 to the government, €150,000 parked in government bonds for 5 years (probably earning next to nothing), and buying at least €350,000 in property (and holding it for at least 5 years).<p>third, if you could cheaply buy the right to live and work in the eu, why would any country stay?  let me explain the scenario.  if i&#x27;m a member country of the eu, i must open my borders to other eu countries, but in exchange those countries are open to me.  why wouldn&#x27;t i want to simply leave and then let the minority of those in my country that want access to the rest to pay a tiny fee?  in fact, if that fee is the same that i&#x27;m paying for all my citizens currently, the government could even pay it for those that want it and save loads of money.  in this scenario, everyone leaves the union because it&#x27;s cheaper to just buy the right for the small few that want it.  if only 1% of your population actually wants to exercise that right in a given year, you could cut your cost from £13b to £130m.<p>the issue is that a foreign country isn&#x27;t going to give you access when your country won&#x27;t give their citizens access on equal terms.  it&#x27;s not an issue of a small fee.  why should a british person willing to pay £185&#x2f;year get access to the eu while a french person willing to pay £185&#x2f;year wouldn&#x27;t get access to the uk?  that&#x27;s the heart of the brexit issue and why a small fee has nothing to do with the problem.  europe isn&#x27;t going to give british people freedom of movement into europe when the uk won&#x27;t give europeans freedom of movement into the uk.  why should they give uk citizens more rights than those of other european nations?<p>the issue is that there aren&#x27;t a lot of alternatives that are in any way realistic.  a realistic solution would mean that uk citizens don&#x27;t get to live&#x2f;work in more places than other eu citizens without some form of consideration proportional to the right.  £185&#x2f;year isn&#x27;t proportional, especially since other eu nations must pay into eu coffers.  i&#x27;m always interested in alternatives, but most alternatives sound more like, &quot;this would be useful and cheap for me and next i&#x27;d like a free, unlimited mobile plan with no strings attached.&quot;  of course it would be useful if the eu let you pay a tiny fee for the right to live and work in the rest of the eu.  would the uk also let europeans pay that fee to live and work in the uk?  no?  ah, there&#x27;s the problem.<p>a realistic solution could be one where a country in the eu allows uk citizens to become citizens of their country provided they renounce all ties to the uk and give up all rights in the uk.  that would allow uk citizens to determine which set of rights they wanted to live under - but they&#x27;d lose uk rights if they chose the european side.  but that&#x27;s not &quot;i get the best of both worlds.&quot;  if you want rights in both the uk and europe, then you need to be willing to offer those rights to eu citizens, not just uk citizens.  to be fair, you might be more than willing to offer that if you were part of the remain camp, but that doesn&#x27;t square with brexit.<p>ultimately, the issue is just that brexit is a rejection of the type of thing you think could be nice.  brexit is a rejection of freedom of movement.  brexit is a rejection of making national citizenship less meaningful.  brexit is a rejection of the idea that you should be able to easily live and work where you want to.  your idea might be cool, but it&#x27;s the opposite of brexit.  maybe we should move to a world where we can freely join &quot;nations&quot; or &quot;unions&quot; that square with what we want in life rather than being citizens of where we were born or whom we were born to.  but that&#x27;s the opposite of the sentiment expressed by brexit which seeks to limit that type of freedom."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "the article makes a halfway decent attempt at the pitfalls of large-scale networks. however, the article doesn&#x27;t come close (in my opinion) to making a case that this will lead them to &quot;fail&quot;.<p>facebook has become massively popular and is still growing. while i am not particularly active on it, i recognize this is atypical. think about how many devs ise fb oauth for example, as it is insanely prolific.<p>networks <i>can</i> fail at any time, but very few have after reaching escape velocity. probably the most notable was aol&#x2f;im and more recently the significant degradation of reddit. networks must seriously mess up accross the 3 main identified categories, and not keep any pace with their users changing needs.<p>i would say the biggest threat to networks at scale, which oddly wasnt really discussed, is a failure to monetize or convert their network into value. many people find twitter useful, for example, but it is rumored to be shopping itself around. if anything, the danger of networks is expecting data and adrevenue to be a sustainable business at scale. obviously, it is a good problem to have 500million plus active users, but it is expensive and difficult. it is harder, one might inagine, to have 50m paying users."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "our team was porting our middleware product to an appliance environment (stripped linux os, hardened image).<p>we had a config script that we used internally for test environments, and were hoping to use it on box until our code covered this part of the setup process.<p>it relied on starting several services in order, and checking certain things were running at various points, by parsing the output of &#x27;ps&#x27;.<p>unfortunately, the appliance used a busybox version of &#x27;ps&#x27; that truncated the output.<p>i ended up writing a shellscript that checked &#x2f;proc manually and echoed a string that would match the main offenders, aliased &#x27;ps&#x27; to the new script, ran the setup and it worked first time.<p>i used it on our nightly test runs for ~ 3 months without issue, until it was properly replaced."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "may be, you are right, users are as good as their reinvestment, with regards to open source. however, reinvestment doesn&#x27;t necessarily have to mean code, money, bug reports or something similar. it could be as simple as, spreading the word. i really appreciate those who share their experiences with a project. it helps make long term decisions easier."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "not supporting safari is just laziness most of the time."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "in piketty&#x27;s model, r is return on capital.  so that means it&#x27;s the return on things like equities (and btw, interest is compounding on investments, don&#x27;t know why you represented otherwise), real estate (piketty is not overly find of the role of rentiers&#x2f;landlords in the economy), machinery and so on.  so the money accrued by the owners of wealth and machinery that is, essentially passive income, or income generated by capital, is r.<p>g is the growth of the economy.  we calculate it as gdp, what he&#x27;s interested in is basically people&#x27;s combined incomes and economic activity that goes with it.<p>the premise that r &gt; g is saying that people who have wealth, their return on that wealth will always be higher than the growth of the economy.  if the economy grows 1%, the return on capital (remember it&#x27;s all capital in the economic sense) will be more than 1%.  now this isn&#x27;t true for all years in all places, but it has been shown to be true in the long run, which is how wealth is accrued quicker by those who already have wealth, and how inequality increases.  keep in mind piketty&#x27;s book is a massive tome.<p>and btw, comparing a rate that&#x27;s calculated as %&#x2f;year to another calculated as %&#x2f;year is mathematically correct.<p>your example is nonsense btw, it almost seems like you&#x27;ve confused r with g, because interest certainly compounds with capital, whereas with income, while you&#x27;ll get increases over time, it generally isn&#x27;t of the same magnitude and relates to labour, of which you have a finite amount."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "`try!(foo)` is roughly equivalent to this (invalid) code:<p><pre><code>    foo().unwrap_or_else({ |e| return err(e) })\n",
       "</code></pre>\n",
       "or in go terms:<p><pre><code>    a := try!(foo)\n",
       "</code></pre>\n",
       "is equivalent to:<p><pre><code>    a, err := foo()\n",
       "    if err != nil {\n",
       "        return nil, err\n",
       "    }\n",
       "</code></pre>\n",
       "basically it will take the result of foo, and if foo returns an error it will return the error itself.<p><a href=\" <LINK> ."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&quot;locking in the losses.&quot;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i really identify with this myself. one of my main learning points about myself is that fretting and prevaricating about work and life is usually worse than just getting on with it."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "for row in b.random_sample(.00001):\n",
    "    display(HTML(row[1]))\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10763434"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9472"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.filter(lambda x: x[0] == 'patio11').count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57663 unique tokens.\n",
      "Shape of data tensor: (59472, 1000)\n",
      "Shape of label tensor: (100000, 2)\n",
      "CPU times: user 50 s, sys: 8.25 s, total: 58.3 s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "SAMPLE_LENGTH = 100000\n",
    "sl = int(SAMPLE_LENGTH/2)\n",
    "non_target_texts = b.map(lambda x: x[1]).take(sl, npartitions=-1)\n",
    "target_texts = b.filter(lambda x: x[0] == 'patio11').map(lambda x: x[1]).take(sl, npartitions=-1)\n",
    "texts = non_target_texts + target_texts\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_SEQUENCE_LENGTH)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray([0]*len(non_target_texts) + [1]*len(target_texts)))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0, 236],\n",
       "       [  0,   0,   0, ..., 516,  14, 380],\n",
       "       [  0,   0,   0, ...,   3, 310, 750],\n",
       "       [  0,   0,   0, ...,   4,  85, 531],\n",
       "       [  0,   0,   0, ...,  67,  11, 136]], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(record):\n",
    "#     text = record[1]\n",
    "#     textl = text.split()\n",
    "#     textl += ['']*100\n",
    "#     textl = textl[:100]\n",
    "#     return (record[0], *textl)\n",
    "\n",
    "# test_sample = b.take(10, compute=False)\n",
    "# test_sample = test_sample.map(tokenize)\n",
    "# test_sample.to_dataframe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob, time\n",
    "# from tqdm import tqdm\n",
    "# import bz2, json\n",
    "# from json import JSONDecodeError\n",
    "\n",
    "# bigstring = b''\n",
    "# for filename in tqdm(glob.glob('data/*bz2')):\n",
    "#     bigstring += bz2.BZ2File(filename).read()\n",
    "    \n",
    "# bigstring[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to HDF5\n",
    "# import bz2, json\n",
    "# from json import JSONDecodeError\n",
    "# b = bz2.BZ2File('data/HNI_2006-10.bz2')\n",
    "# bs = b.read()\n",
    "# bs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bj = []\n",
    "# for l in bs.split(b'\\n'):\n",
    "#     try:\n",
    "#         bj.append(json.loads(l))\n",
    "#     except JSONDecodeError:\n",
    "#         pass\n",
    "# bjc = [x for x in bj if x['type'] == 'comment']\n",
    "# bjc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag\n",
    "# Maybe things like links should be tagged\n",
    "# import re\n",
    "# for i in range(len(bjc)):\n",
    "#     bjc[i]['text'] = bjc[i]['text'].lower()\n",
    "#     bjc[i]['text'] = re.sub('http.*\\w',' <LINK> ',bjc[i]['text'])\n",
    "#     bjc[i]['text'] = re.sub('\\n|\\r|\"|\\'|\\?|&#34;|\\.|\\,','',bjc[i]['text'])\n",
    "\n",
    "# [x['text'] for x in bjc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize\n",
    "# text_list = []\n",
    "# user_list = []\n",
    "# for (text, user) in ((x['text'], x['by']) for x in bjc):\n",
    "#     text_list.append(text.split())\n",
    "#     user_list.append(user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # W2V\n",
    "# from gensim.test.utils import common_texts, get_tmpfile\n",
    "# from gensim.models import Word2Vec\n",
    "# EMBEDDING_DIM = 100\n",
    "\n",
    "# w2vmodel = Word2Vec(text_list, size=EMBEDDING_DIM, window=5, min_count=1, workers=4)\n",
    "# w2vmodel.save(\"word2vec.w2vmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Index\n",
    "# SEQ_LEN = 10\n",
    "\n",
    "# tok_list = []\n",
    "# for text in text_list:\n",
    "#     tok_list.append([])\n",
    "#     for tok in text:\n",
    "#         try:\n",
    "#             tok_list[-1].append(1+w2vmodel.wv.index2word.index(tok))\n",
    "#         except:\n",
    "#             tok_list[-1].append(0)\n",
    "            \n",
    "#     tok_list[-1] = tok_list[-1] + [0]*SEQ_LEN \n",
    "#     tok_list[-1] = tok_list[-1][:SEQ_LEN] \n",
    "            \n",
    "            \n",
    "# tok_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# x_train = np.array(tok_list)\n",
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import to_categorical\n",
    "\n",
    "# y_train = to_categorical([int(x == 'pg') for x in user_list])\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n",
      "CPU times: user 11.2 s, sys: 1.09 s, total: 12.3 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "import os \n",
    "BASE_DIR = '/home/mritter/code/twitter_nlp/newsgroups_data/'\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove')\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57663"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare embedding matrix\n",
    "\n",
    "num_distinct_words = len(tokenizer.word_index) + 1  # For <UNKNOWN> \n",
    "EMBEDDING_DIM = 100  # Dimensions to represent each token\n",
    "\n",
    "embedding_matrix = np.zeros((num_distinct_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > num_distinct_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57664, 100)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape #[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "\n",
    "embedding_layer = Embedding(num_distinct_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "# x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "# x = MaxPooling1D(5)(x)\n",
    "# x = Conv1D(128, 5, activation='relu')(x)\n",
    "# x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47578 samples, validate on 11894 samples\n",
      "Epoch 1/2\n",
      " 1568/47578 [..............................] - ETA: 8:00 - loss: 0.4995 - acc: 0.8355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Worker process 5391 was killed by unknown signal\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-8011161eb9e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#128,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           validation_data=(x_val, y_val))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=32, #128,\n",
    "          epochs=2,\n",
    "          validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build model\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "# # embedding_layer = Embedding(len(model.wv.index2word) + 1,\n",
    "# #                             EMBEDDING_DIM,\n",
    "# #                             weights=[embedding_matrix],\n",
    "# #                             input_length=MAX_SEQUENCE_LENGTH,\n",
    "# #                             trainable=False)\n",
    "\n",
    "# # ValueError: The shape of the input to \"Flatten\" is not fully defined (got (None, 100). \n",
    "# # Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# # embedding_layer = w2vmodel.wv.get_keras_embedding()\n",
    "# # model.add(embedding_layer(EMBEDDING_DIM, input_dim=SEQ_LEN))\n",
    "# model.add(Embedding(1000, 64, input_length=10))\n",
    "# # the model will take as input an integer matrix of size (batch, input_length).\n",
    "# # the largest integer (i.e. word index) in the input should be\n",
    "# # no larger than 999 (vocabulary size).\n",
    "# # now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "\n",
    "# model.add(Flatten())#input_dim=EMBEDDING_DIM*SEQ_LEN))\n",
    "# model.add(Dense(units=5, activation='relu'))\n",
    "# model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='sgd',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12/12 [==============================] - 3s 224ms/step - loss: 0.6918 - acc: 0.5833\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 0s 773us/step - loss: 0.6913 - acc: 0.5833\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 0s 725us/step - loss: 0.6909 - acc: 0.5833\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 0s 570us/step - loss: 0.6904 - acc: 0.5833\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 0s 467us/step - loss: 0.6901 - acc: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa431fbc5c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5030554  0.49694455]\n",
      " [0.5023337  0.49766627]\n",
      " [0.50491714 0.4950828 ]\n",
      " [0.51636297 0.483637  ]\n",
      " [0.49919084 0.50080913]\n",
      " [0.49966925 0.50033075]\n",
      " [0.5031254  0.4968746 ]\n",
      " [0.49960157 0.5003984 ]\n",
      " [0.5059884  0.4940116 ]\n",
      " [0.50231534 0.49768466]\n",
      " [0.50238585 0.49761418]\n",
      " [0.49969432 0.5003057 ]]\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "[0.5833333  0.41666666]\n",
      "[0.6897125691175461, 0.5833333333333334]\n"
     ]
    }
   ],
   "source": [
    "# Test Model\n",
    "predictions = model.predict(x_train)\n",
    "print(predictions)\n",
    "loss_and_metrics = model.evaluate(x_train, y_train, batch_size=1)\n",
    "print(y_train.mean(axis=0))\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
