{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "* The big problem I'm trying to solve here is to make the relatively complex system of NNs for NLP something I cant 'wrap my head around'\n",
    "    * It's about learning, and one of the critical concepts in human learning is 'chunking'. So I've got three layers here: \n",
    "        * Top: \"string of text\" ==(NN system)==> username of interest [Y/N]\n",
    "        * Second: Collection of scripts with input/knobs/dials/outputs\n",
    "        * Third: Code itself, presented as close to linearly as possible\n",
    "        * Important to not try going too deep (I made this mistake with bash tools). Once you've got some solid abstractions that give you flexibility and don't seem to leak, extend rather than deepening knowledge\n",
    "    * Connections to concrete concepts that I already know are also key, so making the inputs/outputs clear in examples using Python datatypes that I'm comfortable with will help grasp the abstract transforms \n",
    "    * Reenforcement is key, so I'll try to copy this and apply it to a different problem almost as soon as I'm done\n",
    "    * The problem with many other systems is that, in an admirable effort to be modular, they force you to jump 3-7 levels deep within functions to get to the actual Python code (the concrete concept). From the main script, it can take several minutes to trace how an input and parameter actually get combined into an output.\n",
    "        * Even if effort was made to document, there's a \"curse of knowledge\" issue that makes it difficult to grasp the particulars without the mental model that the original writer had\n",
    "    * Goal is to find the mental models where I can look at other people's output (code), break it down quickly and accurately, identify what's new about it, and how i could update my design process to take advantage of anything that I don't yet have\n",
    "        * [This twitter thread](https://twitter.com/michael_nielsen/status/1074150124169773056) talks about meeting 'magicians' who are better in ways that you can't comprehend, then working to understand the implicit models that allow them to be 10x better. You probably can't do it just from their work, you need to communicate on a more abstract level. How do I do that here?\n",
    "    * Get solid on one simple approach, and then identify ways to extend it that I don't fully understand yet. Nailing down specific questions, \"I would have expected X, but I'm seeing Y - what's going on?\" is critical\n",
    "* There's huge value in having a single file where you can see everything, whether it's a diagram, makefile or Jupyter notebook\n",
    "* Need to identify what needs to be flexible. Passing a trivial amount of data e2e should be very doable. Then building on that, so that the data is essentially flowing (not moving in massive blocks)\n",
    "* From a documentation standpoint, unit tests waste too much time on the edge cases. At the very least, the top test should always be 'happy path' so you can see what it _should_ look like. Then there needs to be a connection between files\n",
    "    * This is much more possible for data pipelines than application code, so it's under-developed\n",
    "* One big thing that I think I lack is an intuitive sense of what's \"expensive\", in terms of Disk, IO, RAM and Compute (are there other limited resources?)\n",
    "    * Is streaming data from a server going to be a bottleneck?\n",
    "    * Is it computationally expensive to open a bunch of little data files, instead of one big one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/home/mritter/code/twitter_nlp/sandbox_data/'\n",
    "NUM_SAMPLES = 10\n",
    "SKIP_FIRST = 1000\n",
    "test_pct = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNI_2006-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "HNI_2006-12\n",
      "62\n",
      "HNI_2007-02\n",
      "1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download_data.py\n",
    "\n",
    "# loading_dock: [local] sandbox_data.txt, [internet] http server\n",
    "# processing: download, assign IDs, split out test\n",
    "# dial: progress bar\n",
    "# shipping_dock: [local] .h5\n",
    "manifest_filename = 'manifest.txt'\n",
    "server_url = 'https://files.pushshift.io/hackernews/'\n",
    "output_file_base = 'downloaded'\n",
    "\n",
    "\n",
    "from requests import get\n",
    "import bz2, json, tqdm\n",
    "import numpy as np\n",
    "\n",
    "stop = False\n",
    "sample_l = []\n",
    "with open(DATADIR+manifest_filename) as infile:\n",
    "    for line in tqdm.tqdm(infile):\n",
    "        remote_filename = line.split()[1]\n",
    "        print(remote_filename)\n",
    "        as_bytes = get(server_url+remote_filename+'.bz2').content\n",
    "        as_text = bz2.decompress(as_bytes)\n",
    "        for sample in as_text.split(b'\\n'):\n",
    "            if not len(sample): continue\n",
    "            sample_l.append(sample.decode(\"ascii\", \"ignore\"))\n",
    "            if len(sample_l) >= (SKIP_FIRST + NUM_SAMPLES):\n",
    "                stop = True\n",
    "            if stop: break\n",
    "        print(len(sample_l))\n",
    "        if stop: break\n",
    "            \n",
    "sample_l = sample_l[SKIP_FIRST:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "np.random.shuffle(sample_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ix = int(len(sample_l)*test_pct)\n",
    "\n",
    "with open(DATADIR+output_file_base+'_train.jsonl', 'w') as outfile:\n",
    "    outfile.write('\\n'.join(sample_l[test_ix:]))\n",
    "        \n",
    "with open(DATADIR+output_file_base+'_train.jsonl', 'w') as outfile:\n",
    "    outfile.write('\\n'.join(sample_l[:test_ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 mritter mritter 1.3K Jan 26 13:32 sandbox_data/downloaded_test.jsonl\r\n",
      "-rw-rw-r-- 1 mritter mritter  978 Jan 26 16:46 sandbox_data/downloaded_train.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lah sandbox_data/*jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5 sandbox_data/downloaded_test.jsonl\r\n",
      "   4 sandbox_data/downloaded_train.jsonl\r\n",
      "   9 total\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l sandbox_data/*jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> sandbox_data/downloaded_test.jsonl <==\r\n",
      "{\"by\": \"volida\", \"id\": 1009, \"parent\": 856, \"retrieved_on\": 1525542115, \"text\": \"Ebay bought its Chinese clone for hundreds of millions of dollars, which afterwards collapsed because after moving the servers outside China the service's data were going through word filtering (e.g. during login) and there were failures...\\n\", \"time\": 1172412920, \"type\": \"comment\"}\r\n",
      "{\"by\": \"phil\", \"id\": 1003, \"parent\": 955, \"retrieved_on\": 1525542114, \"text\": \"8.3% of what they did in 2005: wow.\", \"time\": 1172399687, \"type\": \"comment\"}\r\n",
      "{\"by\": \"python_kiss\", \"descendants\": 0, \"id\": 1002, \"retrieved_on\": 1525542114, \"score\": 2, \"time\": 1172397259, \"title\": \"The Battle for Mobile Search\", \"type\": \"story\", \"url\": \"http://www.businessweek.com/technology/content/feb2007/tc20070220_828216.htm?campaign_id=rss_daily\"}\r\n",
      "{\"by\": \"rms\", \"descendants\": 3, \"id\": 1005, \"kids\": [1023, 1067], \"retrieved_on\": 1525542114, \"score\": 6, \"time\": 1172400839, \"title\": \"CRV Quickstart:   $250,000 in seed stage financing. How does an 18 year old entrepreneur find references to list on the application?\", \"type\": \"story\", \"url\": \"http://www.crv.com/AboutCRV/QuickStart.html\"}\r\n",
      "{\"by\": \"volida\", \"id\": 1010, \"parent\": 856, \"retrieved_on\": 1525542115, \"text\": \"Ebay bought its Chinese clone for hundreds of millions of dollars\", \"time\": 1172413027, \"type\": \"comment\"}\r\n",
      "\r\n",
      "==> sandbox_data/downloaded_train.jsonl <==\r\n",
      "{\"by\":\"python_kiss\",\"descendants\":0,\"id\":1002,\"retrieved_on\":1525542114,\"score\":2,\"time\":1172397259,\"title\":\"The Battle for Mobile Search\",\"type\":\"story\",\"url\":\"http:\\/\\/www.businessweek.com\\/technology\\/content\\/feb2007\\/tc20070220_828216.htm?campaign_id=rss_daily\"}\r\n",
      "{\"by\":\"rms\",\"descendants\":10,\"id\":1007,\"kids\":[1025],\"retrieved_on\":1525542114,\"score\":9,\"time\":1172404841,\"title\":\"What algorithm does news.YC use to filter spam?\",\"type\":\"story\"}\r\n",
      "{\"by\":\"msgbeepa\",\"descendants\":0,\"id\":1008,\"retrieved_on\":1525542115,\"score\":1,\"time\":1172410393,\"title\":\"Great Way To Find New Job And Career\",\"type\":\"story\",\"url\":\"http:\\/\\/www.wikio.com\\/webinfo?id=13628228\"}\r\n",
      "{\"by\":\"phil\",\"id\":1003,\"parent\":955,\"retrieved_on\":1525542114,\"text\":\"8.3% of what they did in 2005: wow.\",\"time\":1172399687,\"type\":\"comment\"}\r\n",
      "{\"by\":\"volida\",\"id\":1010,\"parent\":856,\"retrieved_on\":1525542115,\"text\":\"Ebay bought its Chinese clone for hundreds of millions of dollars\",\"time\":1172413027,\"type\":\"comment\"}"
     ]
    }
   ],
   "source": [
    "! head sandbox_data/*jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 19490.26it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 9177.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'by': 'phil', 'id': 1003, 'parent': 955, 'retrieved_on': 1525542114, 'text': '8.3% of what they did in 2005: wow.', 'time': 1172399687, 'type': 'comment'}, {'by': 'volida', 'id': 1010, 'parent': 856, 'retrieved_on': 1525542115, 'text': 'Ebay bought its Chinese clone for hundreds of millions of dollars', 'time': 1172413027, 'type': 'comment'}]\n",
      "{1003: ['8', '3%', 'of', 'what', 'they', 'did', 'in', '2005:', 'wow', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], 1010: ['ebay', 'bought', 'its', 'chinese', 'clone', 'for', 'hundreds', 'of', 'millions', 'of', 'dollars', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']}\n",
      "{1003: (0, 1), 1010: (1, 0)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess_w2v_index.py\n",
    "\n",
    "###\n",
    "# PREPROCESSING_STEP\n",
    "###\n",
    "\n",
    "# loading_dock: [JSONL] raw data\n",
    "# processing: filter, split, tag, format labels\n",
    "# lever: training, inference, evaluation, sequence_length\n",
    "# dial: Dask status\n",
    "# shipping_dock: [local] text-only and label-only files with IDs\n",
    "status = 'training'\n",
    "downloaded_filename = 'downloaded'\n",
    "filter_bools = {'type':'story'}  # Lines are filtered out if true\n",
    "split_regex = r' |\\.'\n",
    "remove_regex = r\"\\'|\\\"\"\n",
    "tag_patterns = {'http.*\\w':' <LINK> '}\n",
    "positive_labels = ('pg', 'patio11', 'volida')\n",
    "sequence_length = 300\n",
    "output_file = 'preprocessed'\n",
    "\n",
    "import re\n",
    "\n",
    "data = []\n",
    "with open(DATADIR+downloaded_filename+'_train.jsonl', 'r') as infile:\n",
    "    for line in tqdm.tqdm(infile):\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "for key, value in filter_bools.items():\n",
    "    data = [x for x in data if x[key] != value]\n",
    "\n",
    "texts = {}\n",
    "labels = {}\n",
    "temp_labels = []\n",
    "for row in tqdm.tqdm(data):\n",
    "    temp_text = row['text']\n",
    "    temp_text = temp_text.lower()\n",
    "    for key, value in tag_patterns.items():\n",
    "        temp_text = re.sub(key, value, temp_text)\n",
    "    texts[row['id']] = re.split(split_regex, re.sub(remove_regex, '', temp_text))\n",
    "    labels[row['id']] = (1, 0) if row['by'] in positive_labels else (0, 1)  # Not generalizable\n",
    "\n",
    "for value in texts.values():\n",
    "    value += ['']*(sequence_length-len(value))\n",
    "print(data)\n",
    "print(texts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_insight_: w2v is generated with a simple NN autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-26 17:13:06,875 : INFO : collecting all words and their counts\n",
      "2019-01-26 17:13:06,876 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-26 17:13:06,877 : INFO : collected 18 word types from a corpus of 20 raw words and 2 sentences\n",
      "2019-01-26 17:13:06,877 : INFO : Loading a fresh vocabulary\n",
      "2019-01-26 17:13:06,877 : INFO : min_count=1 retains 18 unique words (100% of original 18, drops 0)\n",
      "2019-01-26 17:13:06,878 : INFO : min_count=1 leaves 20 word corpus (100% of original 20, drops 0)\n",
      "2019-01-26 17:13:06,878 : INFO : deleting the raw counts dictionary of 18 items\n",
      "2019-01-26 17:13:06,879 : INFO : sample=0.001 downsamples 18 most-common words\n",
      "2019-01-26 17:13:06,879 : INFO : downsampling leaves estimated 3 word corpus (15.0% of prior 20)\n",
      "2019-01-26 17:13:06,880 : INFO : estimated required memory for 18 words and 100 dimensions: 23400 bytes\n",
      "2019-01-26 17:13:06,880 : INFO : resetting layer weights\n",
      "2019-01-26 17:13:06,881 : INFO : training model with 2 workers on 18 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-01-26 17:13:06,885 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-26 17:13:06,885 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-26 17:13:06,886 : INFO : EPOCH - 1 : training on 20 raw words (2 effective words) took 0.0s, 2250 effective words/s\n",
      "2019-01-26 17:13:06,887 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-26 17:13:06,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-26 17:13:06,888 : INFO : EPOCH - 2 : training on 20 raw words (5 effective words) took 0.0s, 6155 effective words/s\n",
      "2019-01-26 17:13:06,888 : INFO : training on a 40 raw words (7 effective words) took 0.0s, 1036 effective words/s\n",
      "2019-01-26 17:13:06,889 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# W2V_STEP\n",
    "###\n",
    "\n",
    "# loading_dock: [local] train text\n",
    "# processing: gensim w2v\n",
    "# dial: estimate based on train size\n",
    "# shipping_dock: [local] gensim model\n",
    "output_file = 'w2v'\n",
    "\n",
    "class W2VIter:\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts.values()\n",
    "    def __iter__(self):\n",
    "        for text in self.texts:\n",
    "            yield [token for token in text if token != '']\n",
    "            \n",
    "w2viter = W2VIter(texts)\n",
    "\n",
    "import logging\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "logger= logging.getLogger()\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# TODO This doesn't work yet\n",
    "class EpochFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return record.getMessage().contains('EPOCH')\n",
    "\n",
    "logger.addFilter(EpochFilter())\n",
    "\n",
    "w2v = Word2Vec(w2viter, iter=2, min_count=1, size=100, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'8': <gensim.models.keyedvectors.Vocab at 0x7f6fe62c7828>,\n",
       " '3%': <gensim.models.keyedvectors.Vocab at 0x7f6fe62c73c8>,\n",
       " 'of': <gensim.models.keyedvectors.Vocab at 0x7f6fe6044cc0>,\n",
       " 'what': <gensim.models.keyedvectors.Vocab at 0x7f6fe6044c18>,\n",
       " 'they': <gensim.models.keyedvectors.Vocab at 0x7f6fe6044f28>,\n",
       " 'did': <gensim.models.keyedvectors.Vocab at 0x7f6fe72aa0f0>,\n",
       " 'in': <gensim.models.keyedvectors.Vocab at 0x7f6fe6046ef0>,\n",
       " '2005:': <gensim.models.keyedvectors.Vocab at 0x7f6fe6046f28>,\n",
       " 'wow': <gensim.models.keyedvectors.Vocab at 0x7f6fe601f908>,\n",
       " 'ebay': <gensim.models.keyedvectors.Vocab at 0x7f6fe601f9b0>,\n",
       " 'bought': <gensim.models.keyedvectors.Vocab at 0x7f6fe601f978>,\n",
       " 'its': <gensim.models.keyedvectors.Vocab at 0x7f6fe601f710>,\n",
       " 'chinese': <gensim.models.keyedvectors.Vocab at 0x7f6fe601f550>,\n",
       " 'clone': <gensim.models.keyedvectors.Vocab at 0x7f6fe601f438>,\n",
       " 'for': <gensim.models.keyedvectors.Vocab at 0x7f6fe601f470>,\n",
       " 'hundreds': <gensim.models.keyedvectors.Vocab at 0x7f6fe601f400>,\n",
       " 'millions': <gensim.models.keyedvectors.Vocab at 0x7f6fe601f240>,\n",
       " 'dollars': <gensim.models.keyedvectors.Vocab at 0x7f6fe601f358>}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-26 17:13:09,203 : INFO : saving Word2Vec object under /home/mritter/code/twitter_nlp/sandbox_data/myw2v.w2v, separately None\n",
      "2019-01-26 17:13:09,205 : INFO : not storing attribute vectors_norm\n",
      "2019-01-26 17:13:09,208 : INFO : not storing attribute cum_table\n",
      "2019-01-26 17:13:09,210 : INFO : saved /home/mritter/code/twitter_nlp/sandbox_data/myw2v.w2v\n",
      "2019-01-26 17:13:09,211 : INFO : loading Word2Vec object from /home/mritter/code/twitter_nlp/sandbox_data/myw2v.w2v\n",
      "2019-01-26 17:13:09,213 : INFO : loading wv recursively from /home/mritter/code/twitter_nlp/sandbox_data/myw2v.w2v.wv.* with mmap=None\n",
      "2019-01-26 17:13:09,214 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-01-26 17:13:09,215 : INFO : loading vocabulary recursively from /home/mritter/code/twitter_nlp/sandbox_data/myw2v.w2v.vocabulary.* with mmap=None\n",
      "2019-01-26 17:13:09,216 : INFO : loading trainables recursively from /home/mritter/code/twitter_nlp/sandbox_data/myw2v.w2v.trainables.* with mmap=None\n",
      "2019-01-26 17:13:09,217 : INFO : setting ignored attribute cum_table to None\n",
      "2019-01-26 17:13:09,217 : INFO : loaded /home/mritter/code/twitter_nlp/sandbox_data/myw2v.w2v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00054838 -0.00357793  0.00177963 -0.00220928  0.00305515]\n",
      "of 8 3%\n",
      "Index of \"what\" is: 3\n",
      "Index of \"what\" is: 3\n"
     ]
    }
   ],
   "source": [
    "print(w2v.wv['what'][:5])\n",
    "print(w2v.wv.index2word[0], w2v.wv.index2word[1], w2v.wv.index2word[2])\n",
    "print('Index of \"what\" is: {}'.format(w2v.wv.vocab['what'].index))\n",
    "w2v.save(DATADIR+\"myw2v.w2v\")\n",
    "w2v_loaded = Word2Vec.load(DATADIR+\"myw2v.w2v\")\n",
    "print('Index of \"what\" is: {}'.format(w2v_loaded.wv.vocab['what'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00253542, -0.00189092, -0.00271564,  0.00188061,  0.00152182],\n",
       "       [-0.00137067,  0.00165398,  0.00346244, -0.00419546,  0.0022843 ],\n",
       "       [ 0.00352789, -0.002979  , -0.00073002,  0.00038799,  0.00132004],\n",
       "       [ 0.00054838, -0.00357793,  0.00177963, -0.00220928,  0.00305515],\n",
       "       [ 0.00084377, -0.00152044,  0.00032784,  0.00402925,  0.00302467]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = []\n",
    "for i, token in enumerate(w2v.wv.index2word): l.append(w2v.wv[token])\n",
    "weights = np.array(l)\n",
    "print(weights.shape)\n",
    "weights[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index_text.py\n",
    "\n",
    "# loading_dock: [local] train text, [local] gensim\n",
    "# shipping_dock: [local] text as indexes, [local] 100d w2v array sorted with that index\n",
    "# TODO should I bring the w2v sorting into here?\n",
    "# TODO I need to think about how IDs get passed around here\n",
    "\n",
    "indexed_texts = {}\n",
    "for key, wordlist in texts.items():\n",
    "    indexed_texts[key] = []\n",
    "    for word in wordlist:\n",
    "        if word in w2v.wv.vocab:\n",
    "            a = w2v.wv.vocab[word].index\n",
    "        else:\n",
    "            a = 0\n",
    "        indexed_texts[key].append(a)\n",
    "indexed_texts[1003][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(DATADIR+\"w2v.h5\", \"w\") as f:\n",
    "    dset = f.create_dataset('weights', weights.shape, dtype='f')\n",
    "    dset[:] = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write outputs\n",
    "with h5py.File(DATADIR+\"indexed_text.h5\", \"w\") as f:\n",
    "#     for ix in texts.keys():\n",
    "#         dset = f.create_dataset(str(ix), (300,), dtype='int')\n",
    "#         dset[:] = indexed_texts[key]\n",
    "    f.create_dataset('training_data', (len(indexed_texts), 300), dtype='int', data=list(indexed_texts.values()))\n",
    "    f.create_dataset('ordered_keys', (len(indexed_texts), 1), dtype='int', data=list(indexed_texts.keys()))\n",
    "    f.create_dataset('max_token', (1,), dtype='int', data=weights.shape[0]+1)\n",
    "    f.create_dataset('sequence_length', (1,), dtype='int', data=sequence_length)\n",
    "    \n",
    "\n",
    "with h5py.File(DATADIR+\"indexed_label.h5\", \"w\") as f:\n",
    "#     for ix in labels.keys():\n",
    "#         dset = f.create_dataset(str(ix), (2,), dtype='i')\n",
    "#         dset[:] = labels[ix]\n",
    "    f.create_dataset('training_labels', (len(labels), 2), dtype='int', data=list(labels.values()))\n",
    "    f.create_dataset('ordered_keys', (len(labels), 1), dtype='int', data=list(labels.keys()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  0  3  4  5  6  7  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 9 10 11 12 13 14 15  0 16  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "[[1003]\n",
      " [1010]]\n",
      "300\n",
      "[[0 1]\n",
      " [1 0]]\n",
      "[[1003]\n",
      " [1010]]\n"
     ]
    }
   ],
   "source": [
    "# Try reading\n",
    "with h5py.File(DATADIR+\"indexed_text.h5\", \"r\") as f:\n",
    "    print(f['training_data'][:2])\n",
    "    print(f['ordered_keys'][:2])\n",
    "    print(f['sequence_length'][0])\n",
    "\n",
    "with h5py.File(DATADIR+\"indexed_label.h5\", \"r\") as f:\n",
    "    print(f['training_labels'][:2])\n",
    "    print(f['ordered_keys'][:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 212K\r\n",
      "-rw-rw-r-- 1 mritter mritter 138K Jan 26 17:10 compiled_model.keras\r\n",
      "-rw-rw-r-- 1 mritter mritter 1.3K Jan 26 13:32 downloaded_test.jsonl\r\n",
      "-rw-rw-r-- 1 mritter mritter  978 Jan 26 16:46 downloaded_train.jsonl\r\n",
      "-rw-rw-r-- 1 mritter mritter 2.1K Jan 26 17:13 indexed_label.h5\r\n",
      "-rw-rw-r-- 1 mritter mritter 9.0K Jan 26 17:13 indexed_text.h5\r\n",
      "-rw-rw-r-- 1 mritter mritter 3.2K Jan 23 19:39 manifest.txt\r\n",
      "-rw-rw-r-- 1 mritter mritter  27K Jan 26 17:13 myw2v.w2v\r\n",
      "drwxrwxr-x 2 mritter mritter 4.0K Jan 26 14:24 \u001b[0m\u001b[01;34mtfrecords\u001b[0m/\r\n",
      "-rw-rw-r-- 1 mritter mritter 9.1K Jan 26 17:13 w2v.h5\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh sandbox_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 300, 100)          10000     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 300, 32)           3232      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 19202     \n",
      "=================================================================\n",
      "Total params: 32,434\n",
      "Trainable params: 22,434\n",
      "Non-trainable params: 10,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model.py\n",
    "\n",
    "# loading_dock: 100d w2v array, datafile\n",
    "# lever: params\n",
    "# dial: model.summary()\n",
    "# shipping_dock: [local] compiled model\n",
    "\n",
    "w2v_file = 'w2v.h5'\n",
    "training_file = 'indexed_text.h5'\n",
    "compiled_model = 'compiled_model.keras'\n",
    "\n",
    "with h5py.File(DATADIR+training_file, \"r\") as f:\n",
    "    max_token = f['max_token'][0]\n",
    "    sequence_length = f['sequence_length'][0]\n",
    "\n",
    "with h5py.File(DATADIR+w2v_file, \"r\") as f:\n",
    "    embedding_matrix = f['weights'][()]\n",
    "    embedding_dim = embedding_matrix.shape[1]\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Embedding, Flatten\n",
    "from keras.initializers import Constant\n",
    "from keras.models import Model\n",
    "\n",
    "# model = Sequential()\n",
    "sequence_input = Input(shape=(sequence_length,), dtype='int32')\n",
    "\n",
    "embedded_sequences = Embedding(num_distinct_words,\n",
    "                            embedding_dim,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=sequence_length,\n",
    "                            trainable=False)(sequence_input)\n",
    "\n",
    "x = Dense(units=64, activation='relu')(embedded_sequences)\n",
    "x = Dense(units=32, activation='relu')(embedded_sequences)\n",
    "x = Flatten()(x)\n",
    "preds = Dense(units=2, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "model.save(DATADIR+compiled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6929 - acc: 0.5000\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5000\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "\n",
    "# loading_dock: [local] text as indexes, [local] compiled model\n",
    "# lever: epocs\n",
    "# dial: tensorboard\n",
    "# shipping_dock: [local] saved model\n",
    "\n",
    "training_file = 'indexed_text.h5'\n",
    "compiled_model = 'compiled_model.keras'\n",
    "trained_model = 'trained_model.yaml'\n",
    "trained_weights = 'trained_weights.h5'\n",
    "\n",
    "from keras.callbacks import TensorBoard as tb\n",
    "from datetime import datetime\n",
    "t = datetime.now()\n",
    "tensorboard = tb(log_dir='tensorboard_logs/{:%Y-%m-%d-%H-%M}'.format(t))\n",
    "\n",
    "with h5py.File(DATADIR+training_file, \"r\") as f1:\n",
    "    with h5py.File(DATADIR+\"indexed_label.h5\", \"r\") as f2:\n",
    "        x_train = f1['training_data']  # Note that Keras is special in being able to read the HDF5 _object_\n",
    "        y_train = f2['training_labels']\n",
    "        \n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=64, #128,\n",
    "                  epochs=2,\n",
    "                  shuffle='batch',  # Required for using HDF5\n",
    "#                   validation_data=(x_val, y_val),\n",
    "                  callbacks=[tensorboard])\n",
    "model.save(DATADIR+trained_model)\n",
    "\n",
    "# serialize model to YAML\n",
    "# From https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "model_yaml = model.to_yaml()\n",
    "with open(DATADIR+trained_model, \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(DATADIR+trained_weights)\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load YAML and create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4995369, 0.5004631]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference.py\n",
    "\n",
    "# loading_dock: candidate comment\n",
    "# processing: call preprocess and index, then apply model\n",
    "# shipping_dock: best comment\n",
    "\n",
    "comment_text = \"\"\"\n",
    "Reminder, if you're in the US, the FTC says your eye doctor must give you your prescription after your exam. If a doctor refuses to do so, they can face legal action and penalties.\n",
    "\n",
    "https://www.consumer.ftc.gov/blog/2016/05/buying-prescriptio...\n",
    "\n",
    "That said, I don't think the FTC stipulates what information must appear on the prescription. Many docs leave off your PD (pupillary distance), which is a necessary measurement if you're buying online. Fortunately, there are a variety of easy ways to take this measurement yourself after the exam, although if you're really concerned about precision, you'll want the doctor's measurement.\n",
    "\n",
    "And by the way, it should go without saying, but I'll say it anyway. Although the quality of eyewear available online can be comparable to what you'd get in store ... please don't think an online eye exam is an acceptable substitute for visiting an ophthalmologist in person and getting a comprehensive eye exam! \n",
    "\"\"\"\n",
    "\n",
    "trained_model = 'trained_model.yaml'\n",
    "trained_weights = 'trained_weights.h5'\n",
    "\n",
    "\n",
    "from keras.models import model_from_yaml\n",
    "\n",
    "# load YAML and create model\n",
    "with open(DATADIR+trained_model, 'r') as yaml_file:\n",
    "    loaded_model_yaml = yaml_file.read()\n",
    "    loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(DATADIR+trained_weights)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "indexed_texts = []\n",
    "for word in comment_text.lower().split():\n",
    "    if word in w2v.wv.vocab:\n",
    "        a = w2v.wv.vocab[word].index\n",
    "    else:\n",
    "        a = 0\n",
    "    indexed_texts.append(a)\n",
    "    \n",
    "indexed_texts += [0]*(sequence_length-len(indexed_texts))\n",
    "asarray = np.array([indexed_texts])\n",
    "loaded_model.predict(asarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.py\n",
    "\n",
    "# loading_dock: [local] test file\n",
    "# processing: call inference, then compare to labels \n",
    "# shipping_dock: accuracy printout\n",
    "\n",
    "test_filename = 'downloaded_test'\n",
    "trained_model = 'trained_model'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
