{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mritter/anaconda3/envs/tf_gpu_test04/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5100260174652451250\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1760165888\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 5191295665076974243\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "assert len(backend.tensorflow_backend._get_available_gpus()) > 0\n",
    "\n",
    "# confirm PyTorch sees the GPU\n",
    "from torch import cuda\n",
    "assert cuda.is_available()\n",
    "assert cuda.device_count() > 0\n",
    "print(cuda.get_device_name(cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "# https://files.pushshift.io/hackernews/ (first file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"by\":\"pg\",\"descendants\":15,\"id\":1,\"kids\":[487171,15,234509,454410,82729],\"retrieved_on\":1525541947,'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to HDF5\n",
    "import bz2, json\n",
    "from json import JSONDecodeError\n",
    "b = bz2.BZ2File('data/HNI_2006-10.bz2')\n",
    "bs = b.read()\n",
    "bs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"by\":\"phyllis\",\"descendants\":0,\"id\":3,\"kids\":[454412,531602],\"retrieved_on\":1525541948,\"score\":7,\"time\":1160419233,\"title\":\"Woz Interview: the early days of Apple\",\"type\":\"story\",\"url\":\"http:\\\\/\\\\/www.foundersatwork.com\\\\/stevewozniak.html\"}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.split(b'\\n')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'by': 'sama',\n",
       "  'id': 15,\n",
       "  'kids': [17, 454424],\n",
       "  'parent': 1,\n",
       "  'retrieved_on': 1525541949,\n",
       "  'text': '&#34;the rising star of venture capital&#34; -unknown VC eating lunch on SHR',\n",
       "  'time': 1160423461,\n",
       "  'type': 'comment'},\n",
       " {'by': 'pg',\n",
       "  'id': 17,\n",
       "  'kids': [1079, 454426],\n",
       "  'parent': 15,\n",
       "  'retrieved_on': 1525541950,\n",
       "  'text': 'Is there anywhere to eat on Sandhill Road?',\n",
       "  'time': 1160423565,\n",
       "  'type': 'comment'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bj = []\n",
    "for l in bs.split(b'\\n'):\n",
    "    try:\n",
    "        bj.append(json.loads(l))\n",
    "    except JSONDecodeError:\n",
    "        pass\n",
    "bjc = [x for x in bj if x['type'] == 'comment']\n",
    "bjc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the rising star of venture capital -unknown vc eating lunch on shr',\n",
       " 'is there anywhere to eat on sandhill road',\n",
       " 'its kind of funny that sevin rosen is giving up at the same time sequoia is scoring on this scale',\n",
       " 'this is interesting but the limitations become apparent with one of their example searches:  <link> this comparison shows early stage companies offering a higher salary than fortune xxx companies however these numbers dont seem to indicate total compensation such as benefits and stock or optionsstill a cool use of search technology',\n",
       " 'stay tuned',\n",
       " 'im tuned',\n",
       " 'winnar winnar chicken dinnar!',\n",
       " 'what do you mean  this storys still not #1',\n",
       " 'perhaps if i hadnt told you it was coming <link> ',\n",
       " 'can you do it again',\n",
       " 'its interesting how a simple set of features can make the product seem wholly different new and interesting that and the use of revolutionary and incredible everywhere =)',\n",
       " 'welcome back randall']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tag\n",
    "# Maybe things like links should be tagged\n",
    "import re\n",
    "for i in range(len(bjc)):\n",
    "    bjc[i]['text'] = bjc[i]['text'].lower()\n",
    "    bjc[i]['text'] = re.sub('http.*\\w',' <LINK> ',bjc[i]['text'])\n",
    "    bjc[i]['text'] = re.sub('\\n|\\r|\"|\\'|\\?|&#34;|\\.|\\,','',bjc[i]['text'])\n",
    "\n",
    "[x['text'] for x in bjc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "text_list = []\n",
    "user_list = []\n",
    "for (text, user) in ((x['text'], x['by']) for x in bjc):\n",
    "    text_list.append(text.split())\n",
    "    user_list.append(user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W2V\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "w2vmodel = Word2Vec(text_list, size=EMBEDDING_DIM, window=5, min_count=1, workers=4)\n",
    "w2vmodel.save(\"word2vec.w2vmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of', 'the', 'is', 'this', 'and', 'on', 'interesting', 'a', 'you', 'to']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv.index2word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[84, 17, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index\n",
    "SEQ_LEN = 10\n",
    "\n",
    "tok_list = []\n",
    "for text in text_list:\n",
    "    tok_list.append([])\n",
    "    for tok in text:\n",
    "        try:\n",
    "            tok_list[-1].append(1+w2vmodel.wv.index2word.index(tok))\n",
    "        except:\n",
    "            tok_list[-1].append(0)\n",
    "            \n",
    "    tok_list[-1] = tok_list[-1] + [0]*SEQ_LEN \n",
    "    tok_list[-1] = tok_list[-1][:SEQ_LEN] \n",
    "            \n",
    "            \n",
    "tok_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,  22,  23,   1,  24,  25,  26,  27,  28,  29],\n",
       "       [  3,  31,  32,  10,  33,   6,  34,  35,   0,   0],\n",
       "       [ 11,  36,   1,  37,  12,  38,  39,   3,  40,  41],\n",
       "       [  4,   3,   7,  48,   2,  49,  50,  51,  52,  53],\n",
       "       [ 83,  17,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 84,  17,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 18,  18,  85,  86,   0,   0,   0,   0,   0,   0],\n",
       "       [ 87,  19,   9,  88,   4,  89,  90,  91,  92,   0],\n",
       "       [ 93,  94,  95,  96,  97,   9,  20,  98,  99,  13],\n",
       "       [ 21,   9,  19,  20, 100,   0,   0,   0,   0,   0],\n",
       "       [ 11,   7, 101,   8, 102, 103,   1, 104,  21, 105],\n",
       "       [114, 115, 116,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train = np.array(tok_list)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical([int(x == 'pg') for x in user_list])\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "# embedding_layer = Embedding(len(model.wv.index2word) + 1,\n",
    "#                             EMBEDDING_DIM,\n",
    "#                             weights=[embedding_matrix],\n",
    "#                             input_length=MAX_SEQUENCE_LENGTH,\n",
    "#                             trainable=False)\n",
    "\n",
    "# ValueError: The shape of the input to \"Flatten\" is not fully defined (got (None, 100). \n",
    "# Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# embedding_layer = w2vmodel.wv.get_keras_embedding()\n",
    "# model.add(embedding_layer(EMBEDDING_DIM, input_dim=SEQ_LEN))\n",
    "model.add(Embedding(1000, 64, input_length=10))\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be\n",
    "# no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "\n",
    "model.add(Flatten())#input_dim=EMBEDDING_DIM*SEQ_LEN))\n",
    "model.add(Dense(units=5, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6948 - acc: 0.5000\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 0s 201us/step - loss: 0.6923 - acc: 0.5000\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 0s 290us/step - loss: 0.6900 - acc: 0.5000\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 0s 189us/step - loss: 0.6879 - acc: 0.5000\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 0s 208us/step - loss: 0.6859 - acc: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03f7eac5f8>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49647155 0.5035285 ]\n",
      " [0.49406293 0.50593704]\n",
      " [0.4794362  0.52056384]\n",
      " [0.50747555 0.49252445]\n",
      " [0.49582514 0.5041748 ]\n",
      " [0.50079596 0.49920407]\n",
      " [0.48476064 0.51523936]\n",
      " [0.51129705 0.48870295]\n",
      " [0.54202676 0.4579732 ]\n",
      " [0.46779948 0.5322006 ]\n",
      " [0.50372565 0.49627435]\n",
      " [0.4822092  0.51779085]]\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "[0.5833333  0.41666666]\n",
      "[0.6839474886655807, 0.5]\n"
     ]
    }
   ],
   "source": [
    "# Test Model\n",
    "predictions = model.predict(x_train)\n",
    "print(predictions)\n",
    "loss_and_metrics = model.evaluate(x_train, y_train, batch_size=1)\n",
    "print(y_train.mean(axis=0))\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
