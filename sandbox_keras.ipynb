{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "* There's huge value in having a single file where you can see everything, whether it's a diagram, makefile or Jupyter notebook\n",
    "* Need to identify what needs to be flexible. Passing a trivial amount of data e2e should be very doable\n",
    "* Unit tests waste too much time on the edge cases. At the very least, the top test should always be 'happy path' so you can see what it _should_ look like. Then there needs to be a connection between files\n",
    "    * This is much more possible for data pipelines than application code, so it's under-developed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/home/mritter/code/twitter_nlp/sandbox_data/'\n",
    "NUM_SAMPLES = 10\n",
    "SKIP_FIRST = 1000\n",
    "test_pct = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNI_2006-10\n",
      "61\n",
      "HNI_2006-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:00,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "HNI_2007-02\n",
      "1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download_data.py\n",
    "\n",
    "# loading_dock: [local] sandbox_data.txt, [internet] http server\n",
    "# processing: download, assign IDs, split out test\n",
    "# dial: progress bar\n",
    "# shipping_dock: [local] .h5\n",
    "manifest_filename = 'manifest.txt'\n",
    "server_url = 'https://files.pushshift.io/hackernews/'\n",
    "output_file_base = 'downloaded'\n",
    "\n",
    "\n",
    "from requests import get\n",
    "import bz2, json, tqdm\n",
    "import numpy as np\n",
    "\n",
    "stop = False\n",
    "sample_l = []\n",
    "with open(DATADIR+manifest_filename) as infile:\n",
    "    for line in tqdm.tqdm(infile):\n",
    "        remote_filename = line.split()[1]\n",
    "        print(remote_filename)\n",
    "        as_bytes = get(server_url+remote_filename+'.bz2').content\n",
    "        as_text = bz2.decompress(as_bytes)\n",
    "        for sample in as_text.split(b'\\n'):\n",
    "            if not len(sample): continue\n",
    "            sample_l.append(json.loads(sample))\n",
    "            if len(sample_l) >= (SKIP_FIRST + NUM_SAMPLES):\n",
    "                stop = True\n",
    "            if stop: break\n",
    "        print(len(sample_l))\n",
    "        if stop: break\n",
    "            \n",
    "sample_l = sample_l[SKIP_FIRST:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "np.random.shuffle(sample_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ix = int(len(sample_l)*test_pct)\n",
    "\n",
    "with open(DATADIR+output_file_base+'_train.jsonl', 'w') as outfile:\n",
    "    for entry in sample_l[test_ix:]:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')\n",
    "        \n",
    "with open(DATADIR+output_file_base+'_test.jsonl', 'w') as outfile:\n",
    "    for entry in sample_l[:test_ix]:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> sandbox_data/downloaded_test.jsonl <==\r\n",
      "{\"by\": \"volida\", \"id\": 1009, \"parent\": 856, \"retrieved_on\": 1525542115, \"text\": \"Ebay bought its Chinese clone for hundreds of millions of dollars, which afterwards collapsed because after moving the servers outside China the service's data were going through word filtering (e.g. during login) and there were failures...\\n\", \"time\": 1172412920, \"type\": \"comment\"}\r\n",
      "{\"by\": \"dngrmouse\", \"id\": 1004, \"parent\": 363, \"retrieved_on\": 1525542114, \"text\": \"1. Have it so you can be automatically logged in. I have to manually log in every time I visit the site (using Safari here).<p>2. Just like Reddit does, show the domain each link belongs to. Reddit has this in brackets after the headline, which works fine. Since I don't have much free time, there are some sites that have sub-par content which I avoid reading, and it helps to know where I would end up without having to hover over the link.\", \"time\": 1172400507, \"type\": \"comment\"}\r\n",
      "{\"by\": \"msgbeepa\", \"descendants\": 0, \"id\": 1008, \"retrieved_on\": 1525542115, \"score\": 1, \"time\": 1172410393, \"title\": \"Great Way To Find New Job And Career\", \"type\": \"story\", \"url\": \"http://www.wikio.com/webinfo?id=13628228\"}\r\n",
      "{\"by\": \"rms\", \"descendants\": 10, \"id\": 1007, \"kids\": [1025], \"retrieved_on\": 1525542114, \"score\": 9, \"time\": 1172404841, \"title\": \"What algorithm does news.YC use to filter spam?\", \"type\": \"story\"}\r\n",
      "{\"by\": \"phil\", \"id\": 1003, \"parent\": 955, \"retrieved_on\": 1525542114, \"text\": \"8.3% of what they did in 2005: wow.\", \"time\": 1172399687, \"type\": \"comment\"}\r\n",
      "\r\n",
      "==> sandbox_data/downloaded_train.jsonl <==\r\n",
      "{\"by\": \"volida\", \"id\": 1010, \"parent\": 856, \"retrieved_on\": 1525542115, \"text\": \"Ebay bought its Chinese clone for hundreds of millions of dollars\", \"time\": 1172413027, \"type\": \"comment\"}\r\n",
      "{\"by\": \"rms\", \"id\": 1006, \"parent\": 928, \"retrieved_on\": 1525542114, \"text\": \"It's bad if you come out of the Techstars program without any funding and a non-sustainable company, but then you're probably screwed anyways. VCs are infamously inscrutable; we hear that they are always out to take advantage of naive or underfunded companies.<p>If you're good enough to get further investment after Techstars, you get it from a VC that you already know instead of having to deal with the typical painful negotiations. And if Brad Feld's Foundry Group will give you money, maybe you could get Bay Area VC money. Even better, the best companies will get to reinvest their own profits.\", \"time\": 1172403958, \"type\": \"comment\"}\r\n",
      "{\"by\": \"python_kiss\", \"descendants\": 0, \"id\": 1002, \"retrieved_on\": 1525542114, \"score\": 2, \"time\": 1172397259, \"title\": \"The Battle for Mobile Search\", \"type\": \"story\", \"url\": \"http://www.businessweek.com/technology/content/feb2007/tc20070220_828216.htm?campaign_id=rss_daily\"}\r\n",
      "{\"by\": \"rms\", \"descendants\": 3, \"id\": 1005, \"kids\": [1023, 1067], \"retrieved_on\": 1525542114, \"score\": 6, \"time\": 1172400839, \"title\": \"CRV Quickstart:   $250,000 in seed stage financing. How does an 18 year old entrepreneur find references to list on the application?\", \"type\": \"story\", \"url\": \"http://www.crv.com/AboutCRV/QuickStart.html\"}\r\n",
      "{\"by\": \"python_kiss\", \"descendants\": 0, \"id\": 1001, \"retrieved_on\": 1525542114, \"score\": 3, \"time\": 1172396128, \"title\": \"Wireless: India's Hot, China's Not\", \"type\": \"story\", \"url\": \"http://www.redherring.com/Article.aspx?a=21355\"}\r\n"
     ]
    }
   ],
   "source": [
    "! head sandbox_data/*jsonl"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import h5py\n",
    "with h5py.File(DATADIR+\"downloaded.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\"data\", (10, 9), dtype='S1000', maxshape=(None, 9))\n",
    "    for i in range(len(sample_l)):\n",
    "        f['data'][i, :] = [str(n).encode(\"ascii\", \"ignore\") for n in sample_l[i].values()]\n",
    "\n",
    "with h5py.File(DATADIR+\"downloaded.hdf5\", \"r\") as f:\n",
    "    print(f['mydataset'][()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'sd', 'g', 'd', 'dss', '']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'a|f', 'asdfgfdadssf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 16409.64it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 9228.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'by': 'volida', 'id': 1010, 'parent': 856, 'retrieved_on': 1525542115, 'text': 'Ebay bought its Chinese clone for hundreds of millions of dollars', 'time': 1172413027, 'type': 'comment'}, {'by': 'rms', 'id': 1006, 'parent': 928, 'retrieved_on': 1525542114, 'text': \"It's bad if you come out of the Techstars program without any funding and a non-sustainable company, but then you're probably screwed anyways. VCs are infamously inscrutable; we hear that they are always out to take advantage of naive or underfunded companies.<p>If you're good enough to get further investment after Techstars, you get it from a VC that you already know instead of having to deal with the typical painful negotiations. And if Brad Feld's Foundry Group will give you money, maybe you could get Bay Area VC money. Even better, the best companies will get to reinvest their own profits.\", 'time': 1172403958, 'type': 'comment'}]\n",
      "{1010: ['Ebay', 'bought', 'its', 'Chinese', 'clone', 'for', 'hundreds', 'of', 'millions', 'of', 'dollars', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''], 1006: ['Its', 'bad', 'if', 'you', 'come', 'out', 'of', 'the', 'Techstars', 'program', 'without', 'any', 'funding', 'and', 'a', 'non-sustainable', 'company,', 'but', 'then', 'youre', 'probably', 'screwed', 'anyways', '', 'VCs', 'are', 'infamously', 'inscrutable;', 'we', 'hear', 'that', 'they', 'are', 'always', 'out', 'to', 'take', 'advantage', 'of', 'naive', 'or', 'underfunded', 'companies', '<p>If', 'youre', 'good', 'enough', 'to', 'get', 'further', 'investment', 'after', 'Techstars,', 'you', 'get', 'it', 'from', 'a', 'VC', 'that', 'you', 'already', 'know', 'instead', 'of', 'having', 'to', 'deal', 'with', 'the', 'typical', 'painful', 'negotiations', '', 'And', 'if', 'Brad', 'Felds', 'Foundry', 'Group', 'will', 'give', 'you', 'money,', 'maybe', 'you', 'could', 'get', 'Bay', 'Area', 'VC', 'money', '', 'Even', 'better,', 'the', 'best', 'companies', 'will', 'get', 'to', 'reinvest', 'their', 'own', 'profits', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']}\n",
      "{1010: (1, 0), 1006: (0, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess_data.py\n",
    "\n",
    "# loading_dock: [local] train data\n",
    "# processing: filter, split, tag, format labels\n",
    "# lever: training, inference, evaluation\n",
    "# dial: Dask status\n",
    "# shipping_dock: [local] text-only and label-only files with IDs\n",
    "status = 'training'\n",
    "downloaded_filename = 'downloaded'\n",
    "filter_bools = {'type':'story'}  # Lines are filtered out if true\n",
    "split_regex = r' |\\.'\n",
    "remove_regex = r\"\\'|\\\"\"\n",
    "tag_patterns = {'http.*\\w':' <LINK> '}\n",
    "positive_labels = ('pg', 'patio11', 'volida')\n",
    "output_file = 'preprocessed'\n",
    "\n",
    "import re\n",
    "\n",
    "data = []\n",
    "with open(DATADIR+downloaded_filename+'_train.jsonl', 'r') as infile:\n",
    "    for line in tqdm.tqdm(infile):\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "for key, value in filter_bools.items():\n",
    "    data = [x for x in data if x[key] != value]\n",
    "\n",
    "texts = {}\n",
    "labels = {}\n",
    "temp_labels = []\n",
    "for row in tqdm.tqdm(data):\n",
    "    temp_text = row['text']\n",
    "    for key, value in tag_patterns.items():\n",
    "        temp_text = re.sub(key, value, temp_text)\n",
    "    texts[row['id']] = re.split(split_regex, re.sub(remove_regex, '', temp_text))\n",
    "    labels[row['id']] = (1, 0) if row['by'] in positive_labels else (0, 1)  # Not generalizable\n",
    "\n",
    "for value in texts.values():\n",
    "    value += ['']*(300-len(value))\n",
    "print(data)\n",
    "print(texts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([str(n).encode(\"ascii\", \"ignore\") for n in texts[ix]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(DATADIR+\"preprocessed_text.h5\", \"w\") as f:\n",
    "    for ix in texts.keys():\n",
    "        dset = f.create_dataset(str(ix), (300,), dtype='S100')\n",
    "        dset[:] = [str(n).encode(\"ascii\", \"ignore\") for n in texts[ix]]\n",
    "\n",
    "with h5py.File(DATADIR+\"preprocessed_label.h5\", \"w\") as f:\n",
    "    for ix in labels.keys():\n",
    "        dset = f.create_dataset(str(ix), (2,), dtype='i')\n",
    "        dset[:] = labels[ix]\n",
    "\n",
    "with h5py.File(DATADIR+\"preprocessed_label.h5\", \"r\") as f:\n",
    "    print(f['1010'][()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_w2v.py\n",
    "\n",
    "# loading_dock: [local] train text\n",
    "# processing: gensim w2v\n",
    "# dial: estimate based on train size\n",
    "# shipping_dock: [local] gensim model\n",
    "train_filename = 'preprocessed'\n",
    "output_file = 'w2v'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_text.py\n",
    "\n",
    "# loading_dock: [local] train text, [local] gensim\n",
    "# shipping_dock: [local] text as indexes, [local] 100d w2v array sorted with that index\n",
    "w2v_file = 'w2v'\n",
    "text_file = 'preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "# loading_dock: 100d w2v array\n",
    "# lever: params\n",
    "# dial: model.summary()\n",
    "# shipping_dock: [local] compiled model\n",
    "\n",
    "w2v_file = 'w2v'\n",
    "compiled_model = 'compiled_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "\n",
    "# loading_dock: [local] text as indexes, [local] compiled model\n",
    "# lever: epocs\n",
    "# dial: tensorboard\n",
    "# shipping_dock: [local] saved model\n",
    "\n",
    "text_file = 'preprocessed'\n",
    "compiled_model = 'compiled_model'\n",
    "trained_model = 'trained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference.py\n",
    "\n",
    "# loading_dock: candidate comment\n",
    "# processing: call preprocess and index, then apply model\n",
    "# shipping_dock: best comment\n",
    "\n",
    "comment_text = \"\"\"\n",
    "Reminder, if you're in the US, the FTC says your eye doctor must give you your prescription after your exam. If a doctor refuses to do so, they can face legal action and penalties.\n",
    "\n",
    "https://www.consumer.ftc.gov/blog/2016/05/buying-prescriptio...\n",
    "\n",
    "That said, I don't think the FTC stipulates what information must appear on the prescription. Many docs leave off your PD (pupillary distance), which is a necessary measurement if you're buying online. Fortunately, there are a variety of easy ways to take this measurement yourself after the exam, although if you're really concerned about precision, you'll want the doctor's measurement.\n",
    "\n",
    "And by the way, it should go without saying, but I'll say it anyway. Although the quality of eyewear available online can be comparable to what you'd get in store ... please don't think an online eye exam is an acceptable substitute for visiting an ophthalmologist in person and getting a comprehensive eye exam! \n",
    "\"\"\"\n",
    "\n",
    "trained_model = 'trained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.py\n",
    "\n",
    "# loading_dock: [local] test file\n",
    "# processing: call inference, then compare to labels \n",
    "# shipping_dock: accuracy printout\n",
    "\n",
    "test_filename = 'downloaded_test'\n",
    "trained_model = 'trained_model'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
