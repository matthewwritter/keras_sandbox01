{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# META\n",
    "Each section roughly corresponds to a script. The beginning of each section includes the script name, directions for running it and its arguments. Then the script itself as a cell. Then some exploratory stuff to help make the output understandable (the primary reason this is still in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm environment\n",
    "GPUs can get lost when computer goes to sleep, requires restart\n",
    "Make sure that you're in a conda environment that supports Keras and has tensorflow-gpu installed\n",
    "\n",
    "potentially try: `alias gpureload=\"sudo rmmod nvidia_uvm ; sudo modprobe nvidia_uvm\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF IT DOES NOT WORK, MAY NEED TO RESTART COMPUTER\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "assert len(backend.tensorflow_backend._get_available_gpus()) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**: Browse through [Reddit datasets](https://www.reddit.com/r/datasets/)\n",
    "\n",
    "**Levers**: Search terms\n",
    "\n",
    "**Dials**: Should not take longer than 1h\n",
    "\n",
    "**Output**: Website to download from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find list of datafiles\n",
    "**Input**: Specific website to download from\n",
    "\n",
    "**Levers**: None\n",
    "\n",
    "**Dials**: Filesizes should be >100MB total, File formats should be readable by Python\n",
    "\n",
    "**Output**: List of direct download URL(s) as a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://files.pushshift.io/hackernews/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get  # to make GET request\n",
    "\n",
    "\n",
    "def download(url, file_name):\n",
    "    # open in binary mode\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        # get request\n",
    "        response = get(url)\n",
    "        # write to file\n",
    "        file.write(response.content)\n",
    "\n",
    "download(BASE_URL+'HNI_total_items_by_month.txt', 'data/manifest.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        61 HNI_2006-10\r\n",
      "         1 HNI_2006-12\r\n",
      "      1549 HNI_2007-02\r\n",
      "      6305 HNI_2007-03\r\n",
      "     10335 HNI_2007-04\r\n",
      "      7516 HNI_2007-05\r\n",
      "      6036 HNI_2007-06\r\n",
      "      6410 HNI_2007-07\r\n",
      "     10841 HNI_2007-08\r\n",
      "     12371 HNI_2007-09\r\n"
     ]
    }
   ],
   "source": [
    "! head data/manifest.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk Download\n",
    "**Input**: Local text file of direct download links\n",
    "\n",
    "**Levers**: Stopping criteria (in terms of time, size in memory, or samples). Parallel processes. \n",
    "\n",
    "**Dials**: tqdm or Dask dashboard if set up **<span style=\"color:red\">TODO</span>**\n",
    "\n",
    "**Output**: All datafiles in a local dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134    [209738, HNI_2018-02]\n",
       "135    [237342, HNI_2018-03]\n",
       "136    [237609, HNI_2018-04]\n",
       "137    [237646, HNI_2018-05]\n",
       "138        [17172781, total]\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_list_filename = 'data/manifest.txt'\n",
    "\n",
    "with open(file_list_filename, 'r') as f:\n",
    "    manifest = pd.Series(f.read().split('\\n')).map(str.split)\n",
    "    manifest = manifest[manifest.map(len) > 0].reset_index(drop=True)\n",
    "manifest.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "DOWNLOADING TAKES A LONG TIME",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7016eb65f00f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DOWNLOADING TAKES A LONG TIME'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0murl_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBASE_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'{}.bz2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: DOWNLOADING TAKES A LONG TIME"
     ]
    }
   ],
   "source": [
    "# bulk_file_download.py\n",
    "import os.path\n",
    "\n",
    "assert 0, 'DOWNLOADING TAKES A LONG TIME'\n",
    "\n",
    "url_format = BASE_DIR+'{}.bz2'\n",
    "file_format = 'data/{}.bz2'\n",
    "for size, filename in manifest:\n",
    "    if os.path.isfile(file_format.format(filename)): continue \n",
    "    download(url_format.format(filename), file_format.format(filename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 mritter mritter   27M Jan 19 17:50 data/HNI_2016-11.bz2\r\n",
      "-rw-rw-r-- 1 mritter mritter   26M Jan 19 17:50 data/HNI_2016-12.bz2\r\n",
      "-rw-rw-r-- 1 mritter mritter   29M Jan 20 16:13 data/HNI_2017-01.bz2\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lah data/*bz2 | tail -3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "**Input**: Dir full of  downloaded files\n",
    "\n",
    "**Levers**: Fiat feature engineering decisions as filters and transformations\n",
    "\n",
    "**Dials**: Dask dashboard at [localhost:8787/status]\n",
    "\n",
    "**Output**: Nicely partitioned JSONLs on disk (or something more efficient?)  **<span style=\"color:red\">TODO</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess.py\n",
    "import dask.bag as db\n",
    "from dask.distributed import Client, progress\n",
    "import json, re\n",
    "client = Client(n_workers=8, threads_per_worker=2, memory_limit='6GB')\n",
    "\n",
    "def comment_filter(record):\n",
    "    return (record['type'] == 'comment' \n",
    "            and record.get('deleted', None) == None\n",
    "            and record.get('text', None) != None)\n",
    "\n",
    "def text_transformation(record):\n",
    "    text = record['text'].lower()\n",
    "    text = re.sub('http.*\\w',' <LINK> ',text)\n",
    "    un = record['by'].lower()\n",
    "    return (un, text)\n",
    "\n",
    "b = db.read_text('data/*bz2').map(json.loads).filter(comment_filter)\\\n",
    "      .map(text_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "many &quot;dev bootcamps&quot; have been cropping up in the u.s. i wonder if that is &#x2f; will be a trend in europe?<p>also, hope you&#x27;re doing well morgante :) - fellow &#x27;13"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "i disagree. the c syntax is small and pretty easy to learn but the a learner will be stumped when it comes to installing the compiler, dealing with cryptic compiler errors, pointers and weak typing.<p>i&#x27;d recommend python as it&#x27;s easy to setup on any platform, has a clean easy to read syntax (newbies don&#x27;t need to worry about generators or decorators early on), has a repl and has a ton of good <i>free</i> learning references [1].<p>[1] - <a href=\" <LINK> >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "in the uk, i&#x27;d get rather different numbers: the camry hybrid fuel tank is 70l, petrol is currently ~Â£1.20&#x2f;l, pound at 1.22 to the dollar (thanks brexit), so a full tank would be $102.48.<p>that gives a saving of $74&#x2f;680m or breakeven around the 50k miles point, if my maths is correct."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "CPU times: user 10.8 s, sys: 1.7 s, total: 12.5 s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "for row in b.random_sample(.0000001):  # 2m\n",
    "    display(HTML(row[1]))\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.07 s, sys: 1.8 s, total: 10.9 s\n",
      "Wall time: 1min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10763434"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "b.count().compute()  # 2m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and Split\n",
    "**Input**: JSONLs of texts and labels\n",
    "\n",
    "**Levers**: Exact definition of labels\n",
    "\n",
    "**Dials**: Dask dashboard at [localhost:8787/status]\n",
    "\n",
    "**Output**: .h5 of train/validate (clean up) and token_index  **<span style=\"color:red\">TODO</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "SAMPLE_LENGTH = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.77 s, sys: 755 ms, total: 5.53 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "non_target_texts = b.map(lambda x: x[1]).take(SAMPLE_LENGTH, npartitions=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.47 s, sys: 1.34 s, total: 9.82 s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_texts = b.filter(lambda x: x[0] == 'patio11').map(lambda x: x[1]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tuple(target_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = non_target_texts + tuple(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57663 unique tokens.\n",
      "Shape of data tensor: (59472, 500)\n",
      "Shape of label tensor: (59472, 2)\n",
      "CPU times: user 5.3 s, sys: 104 ms, total: 5.4 s\n",
      "Wall time: 5.16 s\n"
     ]
    }
   ],
   "source": [
    "# tokenize.py\n",
    "%%time\n",
    "tokenizer = Tokenizer(num_words=MAX_SEQUENCE_LENGTH)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "token_index = tokenizer.token_index\n",
    "print('Found %s unique tokens.' % len(token_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray([0]*len(non_target_texts) + [1]*len(target_texts)))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'to': 2,\n",
       " 'a': 3,\n",
       " 'i': 4,\n",
       " 'of': 5,\n",
       " 'and': 6,\n",
       " 'is': 7,\n",
       " 'p': 8,\n",
       " 'that': 9,\n",
       " 'you': 10,\n",
       " 'it': 11,\n",
       " 'in': 12,\n",
       " 'for': 13,\n",
       " 'on': 14,\n",
       " 'this': 15,\n",
       " 'be': 16,\n",
       " 'have': 17,\n",
       " 'with': 18,\n",
       " 'are': 19,\n",
       " 'not': 20,\n",
       " 'if': 21,\n",
       " 'but': 22,\n",
       " 'as': 23,\n",
       " 'your': 24,\n",
       " 'they': 25,\n",
       " 'or': 26,\n",
       " 'my': 27,\n",
       " 'at': 28,\n",
       " 'can': 29,\n",
       " 'an': 30,\n",
       " 'people': 31,\n",
       " 'about': 32,\n",
       " 'do': 33,\n",
       " 'like': 34,\n",
       " 'what': 35,\n",
       " 'was': 36,\n",
       " 'more': 37,\n",
       " 'would': 38,\n",
       " 'one': 39,\n",
       " 'from': 40,\n",
       " 'so': 41,\n",
       " 'just': 42,\n",
       " 'will': 43,\n",
       " 'there': 44,\n",
       " 'all': 45,\n",
       " 'get': 46,\n",
       " 'think': 47,\n",
       " 'by': 48,\n",
       " 'their': 49,\n",
       " \"don't\": 50,\n",
       " 'which': 51,\n",
       " \"it's\": 52,\n",
       " 'me': 53,\n",
       " 'than': 54,\n",
       " 'out': 55,\n",
       " 'we': 56,\n",
       " 'them': 57,\n",
       " 'up': 58,\n",
       " 'some': 59,\n",
       " 'who': 60,\n",
       " 'how': 61,\n",
       " 'time': 62,\n",
       " 'good': 63,\n",
       " 'link': 64,\n",
       " \"i'm\": 65,\n",
       " 'has': 66,\n",
       " 'because': 67,\n",
       " 'when': 68,\n",
       " 'no': 69,\n",
       " 'make': 70,\n",
       " 'other': 71,\n",
       " 'work': 72,\n",
       " 'much': 73,\n",
       " 'really': 74,\n",
       " 'then': 75,\n",
       " 'href': 76,\n",
       " 'x27': 77,\n",
       " 'know': 78,\n",
       " 'very': 79,\n",
       " 'any': 80,\n",
       " 'something': 81,\n",
       " 'want': 82,\n",
       " 'most': 83,\n",
       " 'way': 84,\n",
       " 'use': 85,\n",
       " 'only': 86,\n",
       " 'could': 87,\n",
       " 'even': 88,\n",
       " 'also': 89,\n",
       " 'quot': 90,\n",
       " 'business': 91,\n",
       " 'he': 92,\n",
       " 'money': 93,\n",
       " \"you're\": 94,\n",
       " 'well': 95,\n",
       " 'see': 96,\n",
       " 'had': 97,\n",
       " 'things': 98,\n",
       " 'now': 99,\n",
       " 'many': 100,\n",
       " 'should': 101,\n",
       " 'into': 102,\n",
       " 'need': 103,\n",
       " 'company': 104,\n",
       " 'lot': 105,\n",
       " 'going': 106,\n",
       " 'better': 107,\n",
       " 'been': 108,\n",
       " 'too': 109,\n",
       " '1': 110,\n",
       " 'why': 111,\n",
       " 'web': 112,\n",
       " 'startup': 113,\n",
       " 'were': 114,\n",
       " '2': 115,\n",
       " 'being': 116,\n",
       " 'idea': 117,\n",
       " 'google': 118,\n",
       " 'where': 119,\n",
       " 'right': 120,\n",
       " 'site': 121,\n",
       " 'here': 122,\n",
       " 'probably': 123,\n",
       " \"that's\": 124,\n",
       " 'say': 125,\n",
       " 'actually': 126,\n",
       " 'new': 127,\n",
       " 'does': 128,\n",
       " 'go': 129,\n",
       " 'first': 130,\n",
       " 'thing': 131,\n",
       " 'still': 132,\n",
       " \"i've\": 133,\n",
       " 'great': 134,\n",
       " 'same': 135,\n",
       " 'might': 136,\n",
       " 'software': 137,\n",
       " 'those': 138,\n",
       " 'these': 139,\n",
       " 'yc': 140,\n",
       " 'take': 141,\n",
       " 'someone': 142,\n",
       " 'find': 143,\n",
       " 'us': 144,\n",
       " 'doing': 145,\n",
       " 'users': 146,\n",
       " 'code': 147,\n",
       " 'his': 148,\n",
       " 'years': 149,\n",
       " 'few': 150,\n",
       " 'over': 151,\n",
       " \"doesn't\": 152,\n",
       " 'problem': 153,\n",
       " 'point': 154,\n",
       " 'our': 155,\n",
       " 'two': 156,\n",
       " 'after': 157,\n",
       " 'its': 158,\n",
       " 'etc': 159,\n",
       " 'start': 160,\n",
       " 'off': 161,\n",
       " 'am': 162,\n",
       " 'using': 163,\n",
       " 'day': 164,\n",
       " 'though': 165,\n",
       " 'sure': 166,\n",
       " 'read': 167,\n",
       " 'every': 168,\n",
       " \"can't\": 169,\n",
       " 'own': 170,\n",
       " 'did': 171,\n",
       " 'got': 172,\n",
       " 'working': 173,\n",
       " 'companies': 174,\n",
       " 'pretty': 175,\n",
       " 'best': 176,\n",
       " 's': 177,\n",
       " 'less': 178,\n",
       " 'while': 179,\n",
       " 'enough': 180,\n",
       " 'may': 181,\n",
       " \"i'd\": 182,\n",
       " 'getting': 183,\n",
       " 'never': 184,\n",
       " 'before': 185,\n",
       " 'back': 186,\n",
       " 'big': 187,\n",
       " '3': 188,\n",
       " 'example': 189,\n",
       " \"isn't\": 190,\n",
       " 'seems': 191,\n",
       " 'since': 192,\n",
       " 'without': 193,\n",
       " 'page': 194,\n",
       " 'year': 195,\n",
       " 'down': 196,\n",
       " 'look': 197,\n",
       " 'interesting': 198,\n",
       " 'pay': 199,\n",
       " 'market': 200,\n",
       " 'product': 201,\n",
       " 'startups': 202,\n",
       " 'another': 203,\n",
       " 'having': 204,\n",
       " 'give': 205,\n",
       " 'hard': 206,\n",
       " \"they're\": 207,\n",
       " 'maybe': 208,\n",
       " 'little': 209,\n",
       " 'different': 210,\n",
       " 'news': 211,\n",
       " 'e': 212,\n",
       " 'makes': 213,\n",
       " 'job': 214,\n",
       " 'long': 215,\n",
       " 'user': 216,\n",
       " 'article': 217,\n",
       " 'anything': 218,\n",
       " 'around': 219,\n",
       " 'stuff': 220,\n",
       " \"there's\": 221,\n",
       " 'world': 222,\n",
       " 'post': 223,\n",
       " 'value': 224,\n",
       " 'free': 225,\n",
       " \"didn't\": 226,\n",
       " 'made': 227,\n",
       " 'real': 228,\n",
       " 'rather': 229,\n",
       " 'used': 230,\n",
       " 'through': 231,\n",
       " '5': 232,\n",
       " 'making': 233,\n",
       " 'email': 234,\n",
       " 'data': 235,\n",
       " 'done': 236,\n",
       " 'com': 237,\n",
       " 'bit': 238,\n",
       " 'least': 239,\n",
       " 'bad': 240,\n",
       " 'anyone': 241,\n",
       " 'said': 242,\n",
       " 't': 243,\n",
       " 'always': 244,\n",
       " 'such': 245,\n",
       " 'already': 246,\n",
       " 'system': 247,\n",
       " 'facebook': 248,\n",
       " 'put': 249,\n",
       " 'try': 250,\n",
       " 'number': 251,\n",
       " 'last': 252,\n",
       " 'both': 253,\n",
       " '10': 254,\n",
       " 'ever': 255,\n",
       " 'high': 256,\n",
       " 'come': 257,\n",
       " 'experience': 258,\n",
       " 'next': 259,\n",
       " 'reason': 260,\n",
       " 'language': 261,\n",
       " 'ideas': 262,\n",
       " 'based': 263,\n",
       " 'b': 264,\n",
       " 'end': 265,\n",
       " 'part': 266,\n",
       " 'else': 267,\n",
       " 'trying': 268,\n",
       " '0': 269,\n",
       " 'mean': 270,\n",
       " 'write': 271,\n",
       " 'case': 272,\n",
       " '62': 273,\n",
       " 'c': 274,\n",
       " 'far': 275,\n",
       " 'life': 276,\n",
       " 'either': 277,\n",
       " 'able': 278,\n",
       " 'social': 279,\n",
       " 'between': 280,\n",
       " 'question': 281,\n",
       " 'thought': 282,\n",
       " 'app': 283,\n",
       " 'customers': 284,\n",
       " 'school': 285,\n",
       " 'worth': 286,\n",
       " 'keep': 287,\n",
       " 'kind': 288,\n",
       " 'yes': 289,\n",
       " 'important': 290,\n",
       " 'small': 291,\n",
       " 'tell': 292,\n",
       " 'each': 293,\n",
       " 'everyone': 294,\n",
       " 'person': 295,\n",
       " 'quite': 296,\n",
       " 'internet': 297,\n",
       " 'non': 298,\n",
       " 'instead': 299,\n",
       " 'looking': 300,\n",
       " 'feel': 301,\n",
       " 'thanks': 302,\n",
       " 'buy': 303,\n",
       " 'help': 304,\n",
       " 'means': 305,\n",
       " 'once': 306,\n",
       " 'agree': 307,\n",
       " 're': 308,\n",
       " 'design': 309,\n",
       " 'service': 310,\n",
       " 'fact': 311,\n",
       " 'easy': 312,\n",
       " 'nothing': 313,\n",
       " 'understand': 314,\n",
       " 'search': 315,\n",
       " 'content': 316,\n",
       " 'month': 317,\n",
       " 'programming': 318,\n",
       " 'run': 319,\n",
       " 'true': 320,\n",
       " 'application': 321,\n",
       " 'g': 322,\n",
       " 'away': 323,\n",
       " 'yet': 324,\n",
       " 'course': 325,\n",
       " \"i'll\": 326,\n",
       " 'problems': 327,\n",
       " 'days': 328,\n",
       " 'let': 329,\n",
       " 'project': 330,\n",
       " 'build': 331,\n",
       " 'him': 332,\n",
       " 'everything': 333,\n",
       " 'months': 334,\n",
       " 'name': 335,\n",
       " 'old': 336,\n",
       " 'blog': 337,\n",
       " 'founders': 338,\n",
       " 'almost': 339,\n",
       " 'wrong': 340,\n",
       " '4': 341,\n",
       " 'works': 342,\n",
       " 'sense': 343,\n",
       " 'gets': 344,\n",
       " 'likely': 345,\n",
       " \"you'll\": 346,\n",
       " 'believe': 347,\n",
       " 'again': 348,\n",
       " 'nice': 349,\n",
       " 'list': 350,\n",
       " 'sites': 351,\n",
       " 'comment': 352,\n",
       " 'often': 353,\n",
       " 'x': 354,\n",
       " 'thinking': 355,\n",
       " 'guys': 356,\n",
       " 'useful': 357,\n",
       " 'cost': 358,\n",
       " 'open': 359,\n",
       " 'guy': 360,\n",
       " 'change': 361,\n",
       " 'until': 362,\n",
       " 'possible': 363,\n",
       " 'place': 364,\n",
       " 'times': 365,\n",
       " 'ask': 366,\n",
       " \"won't\": 367,\n",
       " 'book': 368,\n",
       " 'top': 369,\n",
       " 'information': 370,\n",
       " 'similar': 371,\n",
       " '100': 372,\n",
       " 'matter': 373,\n",
       " 'comments': 374,\n",
       " 'model': 375,\n",
       " \"we're\": 376,\n",
       " 'saying': 377,\n",
       " 'add': 378,\n",
       " 'per': 379,\n",
       " 'rails': 380,\n",
       " '000': 381,\n",
       " 'learn': 382,\n",
       " \"wouldn't\": 383,\n",
       " 'love': 384,\n",
       " 'however': 385,\n",
       " 'sell': 386,\n",
       " 'hours': 387,\n",
       " 'large': 388,\n",
       " 'yourself': 389,\n",
       " 'reddit': 390,\n",
       " 'sort': 391,\n",
       " 'guess': 392,\n",
       " 'whether': 393,\n",
       " 'support': 394,\n",
       " 'java': 395,\n",
       " 'writing': 396,\n",
       " 'started': 397,\n",
       " 'call': 398,\n",
       " 'exactly': 399,\n",
       " 'simple': 400,\n",
       " 'lisp': 401,\n",
       " 'given': 402,\n",
       " 'seem': 403,\n",
       " 'ago': 404,\n",
       " 'million': 405,\n",
       " 'create': 406,\n",
       " 'server': 407,\n",
       " 'apps': 408,\n",
       " 'spend': 409,\n",
       " 'microsoft': 410,\n",
       " \"aren't\": 411,\n",
       " 'reading': 412,\n",
       " 'set': 413,\n",
       " 'talk': 414,\n",
       " 'friends': 415,\n",
       " 'care': 416,\n",
       " 'success': 417,\n",
       " 'found': 418,\n",
       " 'college': 419,\n",
       " 'level': 420,\n",
       " '20': 421,\n",
       " 'price': 422,\n",
       " 'three': 423,\n",
       " 'cool': 424,\n",
       " 'looks': 425,\n",
       " 'team': 426,\n",
       " 'customer': 427,\n",
       " 'source': 428,\n",
       " 'community': 429,\n",
       " 'successful': 430,\n",
       " 'marketing': 431,\n",
       " 'interested': 432,\n",
       " 'computer': 433,\n",
       " 'answer': 434,\n",
       " 'development': 435,\n",
       " 'whole': 436,\n",
       " 'line': 437,\n",
       " 'week': 438,\n",
       " 'others': 439,\n",
       " 'needs': 440,\n",
       " 'process': 441,\n",
       " 'technology': 442,\n",
       " 'live': 443,\n",
       " 'second': 444,\n",
       " 'game': 445,\n",
       " 'perhaps': 446,\n",
       " 'pg': 447,\n",
       " 'single': 448,\n",
       " 'folks': 449,\n",
       " 'deal': 450,\n",
       " 'paul': 451,\n",
       " 'online': 452,\n",
       " 'test': 453,\n",
       " 'talking': 454,\n",
       " 'full': 455,\n",
       " 'mind': 456,\n",
       " 'against': 457,\n",
       " 'japanese': 458,\n",
       " \"you've\": 459,\n",
       " 'building': 460,\n",
       " 'side': 461,\n",
       " 'certainly': 462,\n",
       " 'remember': 463,\n",
       " 'lots': 464,\n",
       " 'later': 465,\n",
       " 'seen': 466,\n",
       " 'advice': 467,\n",
       " 'website': 468,\n",
       " 'whatever': 469,\n",
       " 'account': 470,\n",
       " 'founder': 471,\n",
       " 'huge': 472,\n",
       " 'check': 473,\n",
       " 'early': 474,\n",
       " 'amount': 475,\n",
       " 'risk': 476,\n",
       " '6': 477,\n",
       " 'myself': 478,\n",
       " 'smart': 479,\n",
       " 'ones': 480,\n",
       " 'future': 481,\n",
       " 'written': 482,\n",
       " 'funding': 483,\n",
       " 'x2f': 484,\n",
       " 'simply': 485,\n",
       " 'story': 486,\n",
       " 'program': 487,\n",
       " 'ads': 488,\n",
       " 'low': 489,\n",
       " 'word': 490,\n",
       " '60': 491,\n",
       " 'says': 492,\n",
       " 'taking': 493,\n",
       " 'technical': 494,\n",
       " 'particular': 495,\n",
       " 'quality': 496,\n",
       " 'group': 497,\n",
       " 'running': 498,\n",
       " \"he's\": 499,\n",
       " 'businesses': 500,\n",
       " 'points': 501,\n",
       " 'fun': 502,\n",
       " 'tech': 503,\n",
       " 'features': 504,\n",
       " 'industry': 505,\n",
       " '50': 506,\n",
       " 'public': 507,\n",
       " 'today': 508,\n",
       " 'python': 509,\n",
       " 'oh': 510,\n",
       " 'consider': 511,\n",
       " 'several': 512,\n",
       " 'costs': 513,\n",
       " 'please': 514,\n",
       " 'network': 515,\n",
       " 'ruby': 516,\n",
       " 'sounds': 517,\n",
       " 'her': 518,\n",
       " 'comes': 519,\n",
       " 'feature': 520,\n",
       " 'available': 521,\n",
       " 'move': 522,\n",
       " 'ways': 523,\n",
       " 'under': 524,\n",
       " 'wanted': 525,\n",
       " 'sales': 526,\n",
       " 'd': 527,\n",
       " 'show': 528,\n",
       " 'issue': 529,\n",
       " 'general': 530,\n",
       " 'text': 531,\n",
       " 'type': 532,\n",
       " 'become': 533,\n",
       " 'worked': 534,\n",
       " 'common': 535,\n",
       " 'personal': 536,\n",
       " 'applications': 537,\n",
       " 'especially': 538,\n",
       " 'must': 539,\n",
       " 'revenue': 540,\n",
       " 'phone': 541,\n",
       " 'video': 542,\n",
       " 'current': 543,\n",
       " 'yeah': 544,\n",
       " 'totally': 545,\n",
       " 'unless': 546,\n",
       " 'reasons': 547,\n",
       " 'happen': 548,\n",
       " 'couple': 549,\n",
       " 'order': 550,\n",
       " 'version': 551,\n",
       " 'numbers': 552,\n",
       " \"'\": 553,\n",
       " 'definitely': 554,\n",
       " 'selling': 555,\n",
       " 'starting': 556,\n",
       " 'terms': 557,\n",
       " 'easier': 558,\n",
       " '30': 559,\n",
       " 'offer': 560,\n",
       " 'ability': 561,\n",
       " 'services': 562,\n",
       " 'plan': 563,\n",
       " 'average': 564,\n",
       " \"haven't\": 565,\n",
       " 'hope': 566,\n",
       " 'difference': 567,\n",
       " 'paying': 568,\n",
       " 'takes': 569,\n",
       " 'heard': 570,\n",
       " 'she': 571,\n",
       " 'programmers': 572,\n",
       " 'ok': 573,\n",
       " 'solution': 574,\n",
       " 'class': 575,\n",
       " 'paid': 576,\n",
       " 'access': 577,\n",
       " 'investors': 578,\n",
       " 'vc': 579,\n",
       " 'usually': 580,\n",
       " 'goes': 581,\n",
       " 'certain': 582,\n",
       " 'y': 583,\n",
       " 'hand': 584,\n",
       " 'learning': 585,\n",
       " 'co': 586,\n",
       " 'pre': 587,\n",
       " 'windows': 588,\n",
       " 'went': 589,\n",
       " 'difficult': 590,\n",
       " 'home': 591,\n",
       " 'generally': 592,\n",
       " 'half': 593,\n",
       " 'specific': 594,\n",
       " 'words': 595,\n",
       " 'higher': 596,\n",
       " 'results': 597,\n",
       " 'books': 598,\n",
       " \"wasn't\": 599,\n",
       " 'fairly': 600,\n",
       " 'happy': 601,\n",
       " 'front': 602,\n",
       " 'apple': 603,\n",
       " 'basically': 604,\n",
       " 'space': 605,\n",
       " 'built': 606,\n",
       " \"you'd\": 607,\n",
       " 'dollars': 608,\n",
       " 'interest': 609,\n",
       " 'office': 610,\n",
       " 'actual': 611,\n",
       " 'self': 612,\n",
       " 'themselves': 613,\n",
       " 'hackers': 614,\n",
       " 'control': 615,\n",
       " 'share': 616,\n",
       " 'took': 617,\n",
       " 'products': 618,\n",
       " 'figure': 619,\n",
       " 'credit': 620,\n",
       " 'languages': 621,\n",
       " 'sometimes': 622,\n",
       " 'jobs': 623,\n",
       " 'area': 624,\n",
       " 'anyway': 625,\n",
       " \"what's\": 626,\n",
       " 'expect': 627,\n",
       " 'ad': 628,\n",
       " 'client': 629,\n",
       " 'focus': 630,\n",
       " 'plus': 631,\n",
       " 'systems': 632,\n",
       " 'issues': 633,\n",
       " 'investment': 634,\n",
       " 'links': 635,\n",
       " 'form': 636,\n",
       " 'major': 637,\n",
       " 'mostly': 638,\n",
       " 'itself': 639,\n",
       " 'developers': 640,\n",
       " 'hour': 641,\n",
       " 'employees': 642,\n",
       " 'don': 643,\n",
       " 'rate': 644,\n",
       " 'within': 645,\n",
       " 'together': 646,\n",
       " 'send': 647,\n",
       " 'obvious': 648,\n",
       " 'minutes': 649,\n",
       " 'projects': 650,\n",
       " 'poor': 651,\n",
       " \"here's\": 652,\n",
       " 'pick': 653,\n",
       " 'net': 654,\n",
       " 'hear': 655,\n",
       " 'short': 656,\n",
       " 'programmer': 657,\n",
       " 'card': 658,\n",
       " 'japan': 659,\n",
       " 'called': 660,\n",
       " 'questions': 661,\n",
       " 'tried': 662,\n",
       " 'advertising': 663,\n",
       " 'weeks': 664,\n",
       " 'play': 665,\n",
       " 'note': 666,\n",
       " 'above': 667,\n",
       " 'close': 668,\n",
       " 'power': 669,\n",
       " 'sorry': 670,\n",
       " 'wants': 671,\n",
       " 'coming': 672,\n",
       " 'willing': 673,\n",
       " 'click': 674,\n",
       " 'although': 675,\n",
       " 'file': 676,\n",
       " 'rich': 677,\n",
       " 'options': 678,\n",
       " 'php': 679,\n",
       " 'local': 680,\n",
       " 'research': 681,\n",
       " 'popular': 682,\n",
       " 'quickly': 683,\n",
       " 'domain': 684,\n",
       " 'edit': 685,\n",
       " 'hacker': 686,\n",
       " 'choice': 687,\n",
       " 'past': 688,\n",
       " 'result': 689,\n",
       " 'hit': 690,\n",
       " 'wonder': 691,\n",
       " 'platform': 692,\n",
       " 'state': 693,\n",
       " 'happens': 694,\n",
       " 'potential': 695,\n",
       " 'security': 696,\n",
       " 'entire': 697,\n",
       " 'chance': 698,\n",
       " 'music': 699,\n",
       " 'completely': 700,\n",
       " 'option': 701,\n",
       " 'easily': 702,\n",
       " 'imagine': 703,\n",
       " 'cash': 704,\n",
       " 'stop': 705,\n",
       " 'except': 706,\n",
       " 'avoid': 707,\n",
       " 'spent': 708,\n",
       " 'pages': 709,\n",
       " 'bank': 710,\n",
       " 'human': 711,\n",
       " 'came': 712,\n",
       " 'rest': 713,\n",
       " 'cheap': 714,\n",
       " 'currently': 715,\n",
       " 'turn': 716,\n",
       " 'otherwise': 717,\n",
       " 'personally': 718,\n",
       " 'hire': 719,\n",
       " 'man': 720,\n",
       " 'posts': 721,\n",
       " 'soon': 722,\n",
       " 'address': 723,\n",
       " 'outside': 724,\n",
       " 'fast': 725,\n",
       " 'provide': 726,\n",
       " 'view': 727,\n",
       " 'valley': 728,\n",
       " 'term': 729,\n",
       " 'giving': 730,\n",
       " 'engineering': 731,\n",
       " 'asked': 732,\n",
       " 'm': 733,\n",
       " 'government': 734,\n",
       " 'left': 735,\n",
       " 'trust': 736,\n",
       " 'suggest': 737,\n",
       " 'seriously': 738,\n",
       " 'n': 739,\n",
       " 'due': 740,\n",
       " 'particularly': 741,\n",
       " 'wrote': 742,\n",
       " 'charge': 743,\n",
       " 'asking': 744,\n",
       " 'traffic': 745,\n",
       " 'launch': 746,\n",
       " 'main': 747,\n",
       " 'related': 748,\n",
       " 'copy': 749,\n",
       " 'scale': 750,\n",
       " 'opportunity': 751,\n",
       " 'database': 752,\n",
       " 'wait': 753,\n",
       " 'key': 754,\n",
       " 'standard': 755,\n",
       " 'machine': 756,\n",
       " 'equity': 757,\n",
       " 'yahoo': 758,\n",
       " '38': 759,\n",
       " 'students': 760,\n",
       " 'kids': 761,\n",
       " 'eventually': 762,\n",
       " 'paper': 763,\n",
       " 'testing': 764,\n",
       " 'feedback': 765,\n",
       " 'javascript': 766,\n",
       " 'expensive': 767,\n",
       " 'along': 768,\n",
       " 'via': 769,\n",
       " 'recently': 770,\n",
       " 'knowledge': 771,\n",
       " 'young': 772,\n",
       " 'during': 773,\n",
       " 'absolutely': 774,\n",
       " 'browser': 775,\n",
       " 'head': 776,\n",
       " 'apply': 777,\n",
       " 'nobody': 778,\n",
       " 'stock': 779,\n",
       " 'step': 780,\n",
       " 'valuable': 781,\n",
       " 'allow': 782,\n",
       " 'math': 783,\n",
       " 'situation': 784,\n",
       " 'field': 785,\n",
       " 'including': 786,\n",
       " 'tools': 787,\n",
       " '7': 788,\n",
       " 'solve': 789,\n",
       " 'exist': 790,\n",
       " 'living': 791,\n",
       " 'american': 792,\n",
       " 'wow': 793,\n",
       " 'attention': 794,\n",
       " 'gives': 795,\n",
       " '15': 796,\n",
       " 'cannot': 797,\n",
       " 'clear': 798,\n",
       " 'creating': 799,\n",
       " '8': 800,\n",
       " 'told': 801,\n",
       " 'fail': 802,\n",
       " 'karma': 803,\n",
       " 'five': 804,\n",
       " 'linux': 805,\n",
       " 'gmail': 806,\n",
       " 'desktop': 807,\n",
       " 'sound': 808,\n",
       " 'mentioned': 809,\n",
       " 'leave': 810,\n",
       " 'essentially': 811,\n",
       " 'approach': 812,\n",
       " 'obviously': 813,\n",
       " 'core': 814,\n",
       " 'tend': 815,\n",
       " 'advantage': 816,\n",
       " 'discussion': 817,\n",
       " 'degree': 818,\n",
       " 'sign': 819,\n",
       " 'stories': 820,\n",
       " 'performance': 821,\n",
       " 'capital': 822,\n",
       " 'highly': 823,\n",
       " 'spam': 824,\n",
       " 'lack': 825,\n",
       " 'age': 826,\n",
       " 'recommend': 827,\n",
       " 'skills': 828,\n",
       " 'opinion': 829,\n",
       " 'original': 830,\n",
       " 'argument': 831,\n",
       " 'serious': 832,\n",
       " 'management': 833,\n",
       " 'hey': 834,\n",
       " 'uses': 835,\n",
       " 'clients': 836,\n",
       " 'environment': 837,\n",
       " 'worry': 838,\n",
       " 'bunch': 839,\n",
       " 'title': 840,\n",
       " 'vcs': 841,\n",
       " 'family': 842,\n",
       " 'assume': 843,\n",
       " 'multiple': 844,\n",
       " 'require': 845,\n",
       " 'digg': 846,\n",
       " 'legal': 847,\n",
       " 'fund': 848,\n",
       " 'bought': 849,\n",
       " 'luck': 850,\n",
       " 'among': 851,\n",
       " 'science': 852,\n",
       " 'longer': 853,\n",
       " 'fine': 854,\n",
       " 'understanding': 855,\n",
       " 'created': 856,\n",
       " 'articles': 857,\n",
       " 'involved': 858,\n",
       " 'decision': 859,\n",
       " 'professional': 860,\n",
       " 'engineers': 861,\n",
       " 'entrepreneurs': 862,\n",
       " 'lose': 863,\n",
       " 'relevant': 864,\n",
       " \"couldn't\": 865,\n",
       " 'finding': 866,\n",
       " 'amazon': 867,\n",
       " 'employee': 868,\n",
       " 'learned': 869,\n",
       " 'developer': 870,\n",
       " 'iphone': 871,\n",
       " 'dead': 872,\n",
       " \"they'll\": 873,\n",
       " 'awesome': 874,\n",
       " 'needed': 875,\n",
       " 'myspace': 876,\n",
       " 'store': 877,\n",
       " 'prefer': 878,\n",
       " 'audience': 879,\n",
       " \"let's\": 880,\n",
       " 'nbsp': 881,\n",
       " 'box': 882,\n",
       " 'increase': 883,\n",
       " 'knows': 884,\n",
       " 'seeing': 885,\n",
       " 'history': 886,\n",
       " 'thread': 887,\n",
       " 'wish': 888,\n",
       " 'realize': 889,\n",
       " 'law': 890,\n",
       " 'somewhere': 891,\n",
       " 'tax': 892,\n",
       " 'mail': 893,\n",
       " '25': 894,\n",
       " 'seo': 895,\n",
       " 'happened': 896,\n",
       " 'existing': 897,\n",
       " 'friend': 898,\n",
       " 'extra': 899,\n",
       " 'behind': 900,\n",
       " 'ms': 901,\n",
       " 'directly': 902,\n",
       " 'save': 903,\n",
       " 'accounts': 904,\n",
       " 'clearly': 905,\n",
       " 'lines': 906,\n",
       " 'topic': 907,\n",
       " 'somebody': 908,\n",
       " 'mobile': 909,\n",
       " 'four': 910,\n",
       " 'worse': 911,\n",
       " 'across': 912,\n",
       " 'salary': 913,\n",
       " 'mention': 914,\n",
       " 'interview': 915,\n",
       " 'english': 916,\n",
       " 'income': 917,\n",
       " 'room': 918,\n",
       " 'win': 919,\n",
       " 'stupid': 920,\n",
       " 'possibly': 921,\n",
       " 'food': 922,\n",
       " 'taken': 923,\n",
       " 'demo': 924,\n",
       " 'hn': 925,\n",
       " '39': 926,\n",
       " 'cards': 927,\n",
       " 'hate': 928,\n",
       " 'flash': 929,\n",
       " 'games': 930,\n",
       " 'media': 931,\n",
       " 'release': 932,\n",
       " 'hiring': 933,\n",
       " 'depends': 934,\n",
       " 'choose': 935,\n",
       " 'tv': 936,\n",
       " 'author': 937,\n",
       " 'millions': 938,\n",
       " '9': 939,\n",
       " 'buying': 940,\n",
       " 'quick': 941,\n",
       " 'university': 942,\n",
       " 'rates': 943,\n",
       " 'strong': 944,\n",
       " 'effect': 945,\n",
       " 'effort': 946,\n",
       " 'funny': 947,\n",
       " 'benefit': 948,\n",
       " 'implement': 949,\n",
       " 'significant': 950,\n",
       " \"they've\": 951,\n",
       " 'known': 952,\n",
       " 'response': 953,\n",
       " 'message': 954,\n",
       " 'html': 955,\n",
       " 'return': 956,\n",
       " 'consulting': 957,\n",
       " 'api': 958,\n",
       " 'size': 959,\n",
       " 'hardware': 960,\n",
       " 'll': 961,\n",
       " 'failure': 962,\n",
       " 'competition': 963,\n",
       " 'required': 964,\n",
       " 'education': 965,\n",
       " 'places': 966,\n",
       " 'follow': 967,\n",
       " 'button': 968,\n",
       " 'random': 969,\n",
       " 'tool': 970,\n",
       " 'cut': 971,\n",
       " 'sold': 972,\n",
       " 'nearly': 973,\n",
       " 'basic': 974,\n",
       " 'women': 975,\n",
       " 'bring': 976,\n",
       " 'moment': 977,\n",
       " 'bet': 978,\n",
       " 'bingo': 979,\n",
       " 'designed': 980,\n",
       " '12': 981,\n",
       " 'strategy': 982,\n",
       " 'reality': 983,\n",
       " 'zero': 984,\n",
       " 'faster': 985,\n",
       " 'whose': 986,\n",
       " \"we'll\": 987,\n",
       " 'vote': 988,\n",
       " 'position': 989,\n",
       " 'billion': 990,\n",
       " 'financial': 991,\n",
       " 'ycombinator': 992,\n",
       " 'changes': 993,\n",
       " 'goal': 994,\n",
       " 'cases': 995,\n",
       " 'resources': 996,\n",
       " 'interface': 997,\n",
       " 'harder': 998,\n",
       " 'servers': 999,\n",
       " 'thousands': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 64 ms, total: 64 ms\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import h5py\n",
    "\n",
    "with h5py.File('data/padded_data.h5', 'w') as h5f:\n",
    "    h5f.create_dataset('dataset_1', data=data)\n",
    "\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.81 ms, sys: 0 ns, total: 3.81 ms\n",
      "Wall time: 3.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import h5py\n",
    "\n",
    "with h5py.File('data/labels.h5', 'w') as h5f:\n",
    "    h5f.create_dataset('dataset_1', data=labels)\n",
    "\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47578, 500)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  17,   9,  20],\n",
       "       [  0,   0,   0, ..., 135,   2,  10],\n",
       "       [  0,   0,   0, ..., 104,  34, 118],\n",
       "       [  0,   0,   0, ...,  23,   3,   5],\n",
       "       [  0,   0,   0, ..., 375,  14,  64]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "**Input**: Word index, Trained Word2Vec\n",
    "\n",
    "**Levers**: None\n",
    "\n",
    "**Dials**: None\n",
    "\n",
    "**Output**: Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n",
      "CPU times: user 10.2 s, sys: 632 ms, total: 10.8 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "# create_embedding_matrix.py\n",
    "%%time\n",
    "# This is actually super fast\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "import os \n",
    "GLOVE_DIR = '/home/mritter/code/twitter_nlp/newsgroups_data/glove'\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57663"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.2 ms, sys: 11.9 ms, total: 86.1 ms\n",
      "Wall time: 85.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# prepare embedding matrix\n",
    "\n",
    "num_distinct_words = len(tokenizer.token_index) + 1  # For <UNKNOWN> \n",
    "EMBEDDING_DIM = tuple(embeddings_index.values())[0].shape[0]  # Dimensions to represent each token\n",
    "\n",
    "embedding_matrix = np.zeros((num_distinct_words, EMBEDDING_DIM))\n",
    "for word, i in token_index.items():\n",
    "    if i > num_distinct_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57664, 100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 87.5 ms, total: 87.5 ms\n",
      "Wall time: 85.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import h5py\n",
    "\n",
    "with h5py.File('data/whole_data.h5', 'w') as h5f:\n",
    "    h5f.create_dataset('embedding_matrix', data=embedding_matrix)\n",
    "    h5f.create_dataset('x_train', data=x_train)\n",
    "    h5f.create_dataset('y_train', data=y_train)\n",
    "    h5f.create_dataset('x_val', data=x_val)\n",
    "    h5f.create_dataset('y_val', data=y_val)\n",
    "\n",
    "h5f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Code\n",
    "**Input**: Embedding Matrix\n",
    "\n",
    "**Levers**: Every layer decision and parameter\n",
    "\n",
    "**Dials**: Whether model compiles. Number of parameters in `summary`\n",
    "\n",
    "**Output**: Compiled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "\n",
    "embedding_layer = Embedding(num_distinct_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190121-15-09'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "t = datetime.now()\n",
    "'{:%Y-%m-%d-%H-%M}'.format(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "**Input**: Featuers, Labels, Compiled Model\n",
    "\n",
    "**Levers**: Batch Size, Epochs\n",
    "\n",
    "**Dials**: Tensorboard at [localhost:6006]\n",
    "\n",
    "**Output**: Trained Model (both in RAM and on disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47578 samples, validate on 11894 samples\n",
      "Epoch 1/2\n",
      "47578/47578 [==============================] - 13s 281us/step - loss: 0.1537 - acc: 0.9533 - val_loss: 0.3822 - val_acc: 0.9058\n",
      "Epoch 2/2\n",
      "47578/47578 [==============================] - 13s 281us/step - loss: 0.1545 - acc: 0.9571 - val_loss: 0.3971 - val_acc: 0.9042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f90b1469470>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a TensorBoard instance with the path to the logs directory\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard as tb\n",
    "from datetime import datetime\n",
    "t = datetime.now()\n",
    "tensorboard = tb(log_dir='tensorboard_logs/{:%Y-%m-%d-%H-%M}'.format(t))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, #128,\n",
    "          epochs=2,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47578, 500)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>prob_patio</th>\n",
       "      <th>original_index</th>\n",
       "      <th>original_text</th>\n",
       "      <th>is_patio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8147</td>\n",
       "      <td>0.82</td>\n",
       "      <td>30330</td>\n",
       "      <td>rtfa. the blog post lists a 2-3 word blurb for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5780</td>\n",
       "      <td>0.76</td>\n",
       "      <td>28511</td>\n",
       "      <td>you can get most of that info elsewhere, thoug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6093</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7990</td>\n",
       "      <td>actual karma is defined as \"the total effect o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8374</td>\n",
       "      <td>0.74</td>\n",
       "      <td>26211</td>\n",
       "      <td>ah yes, but that is to buy military products w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3322</td>\n",
       "      <td>0.74</td>\n",
       "      <td>16147</td>\n",
       "      <td>low millions probably means low ones-of-millio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  prob_patio  original_index  \\\n",
       "0   8147        0.82           30330   \n",
       "1   5780        0.76           28511   \n",
       "2   6093        0.76            7990   \n",
       "3   8374        0.74           26211   \n",
       "4   3322        0.74           16147   \n",
       "\n",
       "                                       original_text  is_patio  \n",
       "0  rtfa. the blog post lists a 2-3 word blurb for...         0  \n",
       "1  you can get most of that info elsewhere, thoug...         0  \n",
       "2  actual karma is defined as \"the total effect o...         0  \n",
       "3  ah yes, but that is to buy military products w...         0  \n",
       "4  low millions probably means low ones-of-millio...         0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a feel for the outputs\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "samples = 10000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'prob_patio': model.predict(x_train[:samples])[:, 1].round(2),\n",
    "    'original_index': indices[:samples],\n",
    "    'original_text': [texts[i] for i in indices[:samples]],\n",
    "    'is_patio': labels[:samples,1].astype(int),\n",
    "})\n",
    "most_similar = df[df.is_patio == 0].sort_values('prob_patio', ascending=False).reset_index()\n",
    "most_similar.head()\n",
    "# loss_and_metrics = model.evaluate(x_train, y_train, batch_size=1)\n",
    "# print(y_train.mean(axis=0))\n",
    "# print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = most_similar.iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "see also: \"google wants to do for radio what it did for the web\" and \"google wants to do for newspapers what it did for the web.\""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML((next(i)[1].original_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (bad object header version number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-41de02fbbdb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_models/model_lstm01.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (bad object header version number)"
     ]
    }
   ],
   "source": [
    "m = keras.models.load_model('saved_models/model_lstm01.h5')\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
