{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "* The big problem I'm trying to solve here is to make the relatively complex system of NNs for NLP something I cant 'wrap my head around'\n",
    "    * It's about learning, and one of the critical concepts in human learning is 'chunking'. So I've got three layers here: \n",
    "        * Top: \"string of text\" ==(NN system)==> username of interest [Y/N]\n",
    "        * Second: Collection of scripts with input/knobs/dials/outputs\n",
    "        * Third: Code itself, presented as close to linearly as possible\n",
    "        * Important to not try going too deep (I made this mistake with bash tools). Once you've got some solid abstractions that give you flexibility and don't seem to leak, extend rather than deepening knowledge\n",
    "    * Connections to concrete concepts that I already know are also key, so making the inputs/outputs clear in examples using Python datatypes that I'm comfortable with will help grasp the abstract transforms \n",
    "    * Reenforcement is key, so I'll try to copy this and apply it to a different problem almost as soon as I'm done\n",
    "    * The problem with many other systems is that, in an admirable effort to be modular, they force you to jump 3-7 levels deep within functions to get to the actual Python code (the concrete concept). From the main script, it can take several minutes to trace how an input and parameter actually get combined into an output.\n",
    "        * Even if effort was made to document, there's a \"curse of knowledge\" issue that makes it difficult to grasp the particulars without the mental model that the original writer had\n",
    "    * Goal is to find the mental models where I can look at other people's output (code), break it down quickly and accurately, identify what's new about it, and how i could update my design process to take advantage of anything that I don't yet have\n",
    "        * [This twitter thread](https://twitter.com/michael_nielsen/status/1074150124169773056) talks about meeting 'magicians' who are better in ways that you can't comprehend, then working to understand the implicit models that allow them to be 10x better. You probably can't do it just from their work, you need to communicate on a more abstract level. How do I do that here?\n",
    "    * Get solid on one simple approach, and then identify ways to extend it that I don't fully understand yet. Nailing down specific questions, \"I would have expected X, but I'm seeing Y - what's going on?\" is critical\n",
    "* There's huge value in having a single file where you can see everything, whether it's a diagram, makefile or Jupyter notebook\n",
    "* Need to identify what needs to be flexible. Passing a trivial amount of data e2e should be very doable. Then building on that, so that the data is essentially flowing (not moving in massive blocks)\n",
    "* From a documentation standpoint, unit tests waste too much time on the edge cases. At the very least, the top test should always be 'happy path' so you can see what it _should_ look like. Then there needs to be a connection between files\n",
    "    * This is much more possible for data pipelines than application code, so it's under-developed\n",
    "* One big thing that I think I lack is an intuitive sense of what's \"expensive\", in terms of Disk, IO, RAM and Compute (are there other limited resources?)\n",
    "    * Is streaming data from a server going to be a bottleneck?\n",
    "    * Is it computationally expensive to open a bunch of little data files, instead of one big one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# META\n",
    "###\n",
    "\n",
    "import h5py, bz2, json, tqdm, re\n",
    "import numpy as np\n",
    "\n",
    "DATADIR = '/home/mritter/code/twitter_nlp/sandbox_data02/'\n",
    "NUM_SAMPLES = 10\n",
    "SKIP_FIRST = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNI_2006-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "HNI_2006-12\n",
      "62\n",
      "HNI_2007-02\n",
      "1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download_data.py\n",
    "\n",
    "# Input\n",
    "manifest_filename = 'manifest.txt'\n",
    "server_url = 'https://files.pushshift.io/hackernews/'\n",
    "\n",
    "# Knobs\n",
    "test_pct = .5\n",
    "\n",
    "# Output\n",
    "raw_data = 'raw_data'\n",
    "\n",
    "\n",
    "from requests import get\n",
    "\n",
    "np.random.seed = 42\n",
    "stop = False\n",
    "sample_l = []\n",
    "with open(DATADIR+manifest_filename) as infile:\n",
    "    for line in tqdm.tqdm(infile):  # Dial\n",
    "        remote_filename = line.split()[1]\n",
    "        print(remote_filename)\n",
    "        as_bytes = get(server_url+remote_filename+'.bz2').content\n",
    "        as_text = bz2.decompress(as_bytes)\n",
    "        for sample in as_text.split(b'\\n'):\n",
    "            if not len(sample): continue\n",
    "            sample_l.append(sample.decode(\"ascii\", \"ignore\"))\n",
    "            if len(sample_l) >= (SKIP_FIRST + NUM_SAMPLES):\n",
    "                stop = True\n",
    "            if stop: break\n",
    "        print(len(sample_l))\n",
    "        if stop: break\n",
    "            \n",
    "sample_l = sample_l[SKIP_FIRST:]\n",
    "np.random.shuffle(sample_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"by\":\"rms\",\"id\":1006,\"parent\":928,\"retrieved_on\":1525542114,\"text\":\"It's bad if you come out of the Techstars program without any funding and a non-sustainable company, but then you're probably screwed anyways. VCs are infamously inscrutable; we hear that they are always out to take advantage of naive or underfunded companies.<p>If you're good enough to get further investment after Techstars, you get it from a VC that you already know instead of having to deal with the typical painful negotiations. And if Brad Feld's Foundry Group will give you money, maybe you could get Bay Area VC money. Even better, the best companies will get to reinvest their own profits.\",\"time\":1172403958,\"type\":\"comment\"}\n",
      "== shuffling ==\n",
      "{\"by\":\"msgbeepa\",\"descendants\":0,\"id\":1008,\"retrieved_on\":1525542115,\"score\":1,\"time\":1172410393,\"title\":\"Great Way To Find New Job And Career\",\"type\":\"story\",\"url\":\"http:\\/\\/www.wikio.com\\/webinfo?id=13628228\"}\n"
     ]
    }
   ],
   "source": [
    "print(sample_l[0])\n",
    "print('== shuffling ==')\n",
    "np.random.seed = 42\n",
    "np.random.shuffle(sample_l)\n",
    "print(sample_l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ix = int(len(sample_l)*test_pct)\n",
    "\n",
    "with open(DATADIR+raw_data+'_train.jsonl', 'w') as outfile:\n",
    "    outfile.write('\\n'.join(sample_l[test_ix:]))\n",
    "        \n",
    "with open(DATADIR+raw_data+'_test.jsonl', 'w') as outfile:\n",
    "    outfile.write('\\n'.join(sample_l[:test_ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 mritter mritter 1016 Jan 26 20:59 sandbox_data/raw_data_test.jsonl\r\n",
      "-rw-rw-r-- 1 mritter mritter 2.1K Jan 26 20:59 sandbox_data/raw_data_train.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lah sandbox_data/*jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4 sandbox_data/raw_data_test.jsonl\r\n",
      "   4 sandbox_data/raw_data_train.jsonl\r\n",
      "   8 total\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l sandbox_data/*jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> sandbox_data/raw_data_test.jsonl <==\r\n",
      "{\"by\":\"phil\",\"id\":1003,\"parent\":955,\"retrieved_on\":1525542114,\"text\":\"8.3% of what they did in 2005: wow.\",\"time\":1172399687,\"type\":\"comment\"}\r\n",
      "{\"by\":\"python_kiss\",\"descendants\":0,\"id\":1002,\"retrieved_on\":1525542114,\"score\":2,\"time\":1172397259,\"title\":\"The Battle for Mobile Search\",\"type\":\"story\",\"url\":\"http:\\/\\/www.businessweek.com\\/technology\\/content\\/feb2007\\/tc20070220_828216.htm?campaign_id=rss_daily\"}\r\n",
      "{\"by\":\"volida\",\"id\":1010,\"parent\":856,\"retrieved_on\":1525542115,\"text\":\"Ebay bought its Chinese clone for hundreds of millions of dollars\",\"time\":1172413027,\"type\":\"comment\"}\r\n",
      "{\"by\":\"msgbeepa\",\"descendants\":0,\"id\":1008,\"retrieved_on\":1525542115,\"score\":1,\"time\":1172410393,\"title\":\"Great Way To Find New Job And Career\",\"type\":\"story\",\"url\":\"http:\\/\\/www.wikio.com\\/webinfo?id=13628228\"}\r\n",
      "{\"by\":\"python_kiss\",\"descendants\":0,\"id\":1001,\"retrieved_on\":1525542114,\"score\":3,\"time\":1172396128,\"title\":\"Wireless: India's Hot, China's Not\",\"type\":\"story\",\"url\":\"http:\\/\\/www.redherring.com\\/Article.aspx?a=21355\"}\r\n",
      "==> sandbox_data/raw_data_train.jsonl <==\r\n",
      "{\"by\":\"volida\",\"id\":1009,\"parent\":856,\"retrieved_on\":1525542115,\"text\":\"Ebay bought its Chinese clone for hundreds of millions of dollars, which afterwards collapsed because after moving the servers outside China the service's data were going through word filtering (e.g. during login) and there were failures...\\n\",\"time\":1172412920,\"type\":\"comment\"}\r\n",
      "{\"by\":\"rms\",\"descendants\":3,\"id\":1005,\"kids\":[1023,1067],\"retrieved_on\":1525542114,\"score\":6,\"time\":1172400839,\"title\":\"CRV Quickstart:   $250,000 in seed stage financing. How does an 18 year old entrepreneur find references to list on the application?\",\"type\":\"story\",\"url\":\"http:\\/\\/www.crv.com\\/AboutCRV\\/QuickStart.html\"}\r\n",
      "{\"by\":\"rms\",\"descendants\":10,\"id\":1007,\"kids\":[1025],\"retrieved_on\":1525542114,\"score\":9,\"time\":1172404841,\"title\":\"What algorithm does news.YC use to filter spam?\",\"type\":\"story\"}\r\n",
      "{\"by\":\"dngrmouse\",\"id\":1004,\"parent\":363,\"retrieved_on\":1525542114,\"text\":\"1. Have it so you can be automatically logged in. I have to manually log in every time I visit the site (using Safari here).<p>2. Just like Reddit does, show the domain each link belongs to. Reddit has this in brackets after the headline, which works fine. Since I don't have much free time, there are some sites that have sub-par content which I avoid reading, and it helps to know where I would end up without having to hover over the link.\",\"time\":1172400507,\"type\":\"comment\"}\r\n",
      "{\"by\":\"rms\",\"id\":1006,\"parent\":928,\"retrieved_on\":1525542114,\"text\":\"It's bad if you come out of the Techstars program without any funding and a non-sustainable company, but then you're probably screwed anyways. VCs are infamously inscrutable; we hear that they are always out to take advantage of naive or underfunded companies.<p>If you're good enough to get further investment after Techstars, you get it from a VC that you already know instead of having to deal with the typical painful negotiations. And if Brad Feld's Foundry Group will give you money, maybe you could get Bay Area VC money. Even better, the best companies will get to reinvest their own profits.\",\"time\":1172403958,\"type\":\"comment\"}"
     ]
    }
   ],
   "source": [
    "! head sandbox_data/*jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 6691.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess_txt.py\n",
    "\n",
    "# Input\n",
    "raw_data = 'raw_data_train.jsonl'\n",
    "\n",
    "# Knobs\n",
    "status = 'training'\n",
    "filter_bool = ('type', 'comment') \n",
    "split_regex = r' |\\.'\n",
    "remove_regex = r\"\\'|\\\"|,|\\.|\\n|\\/|&#\\d\\d;|\\(|\\)\"\n",
    "tag_patterns = {'http.*\\w':' <LINK> '}\n",
    "positive_labels = ('pg', 'patio11', 'volida')\n",
    "sequence_length = 300\n",
    "\n",
    "# Output\n",
    "preprocessed_data = 'preprocessed.txt'\n",
    "label_file = 'label_and_index.h5'\n",
    "\n",
    "import re\n",
    "\n",
    "labels = []\n",
    "original_ids = []\n",
    "\n",
    "with open(DATADIR+raw_data, 'r') as infile:\n",
    "    with open(DATADIR+preprocessed_data, 'w') as outfile:\n",
    "        for line in tqdm.tqdm(infile):  # Dial\n",
    "            line_json = json.loads(line)\n",
    "\n",
    "            if line_json[filter_bool[0]] != filter_bool[1]: continue\n",
    "            temp_text = line_json['text']\n",
    "            temp_text = temp_text.lower()\n",
    "            for key, value in tag_patterns.items():\n",
    "                temp_text = re.sub(key, value, temp_text)\n",
    "            text = re.split(split_regex, re.sub(remove_regex, '', temp_text))\n",
    "            print(len(text))\n",
    "            text += ['']*(sequence_length-len(text))\n",
    "            text += ['\\n']\n",
    "            outfile.write(','.join(text))\n",
    "            \n",
    "            if status == 'training':\n",
    "                labels.append((1, 0) if line_json['by'] in positive_labels else (0, 1))  # Not generalizable\n",
    "                original_ids.append(line_json['id'])\n",
    "            \n",
    "if status == 'training':\n",
    "    with h5py.File(DATADIR+label_file, \"w\") as f:\n",
    "        f.create_dataset('training_labels', (len(labels), 2), dtype='int', data=labels)\n",
    "        f.create_dataset('ordered_keys', (len(original_ids), 1), dtype='int', data=original_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebay,bought,its,chinese,clone,for,hundreds,of,millions,of,dollars,which,afterwards,collapsed,because,after,moving,the,servers,outside,china,the,services,data,were,going,through,word,filtering,(eg,during,login),and,there,were,failures,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\r\n",
      "1,have,it,so,you,can,be,automatically,logged,in,i,have,to,manually,log,in,every,time,i,visit,the,site,(using,safari,here)<p>2,just,like,reddit,does,show,the,domain,each,link,belongs,to,reddit,has,this,in,brackets,after,the,headline,which,works,fine,since,i,dont,have,much,free,time,there,are,some,sites,that,have,sub-par,content,which,i,avoid,reading,and,it,helps,to,know,where,i,would,end,up,without,having,to,hover,over,the,link,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 sandbox_data/preprocessed.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_insight_: w2v is generated with a simple NN autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-27 06:31:10,086 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-01-27 06:31:10,087 : INFO : collecting all words and their counts\n",
      "2019-01-27 06:31:10,088 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-27 06:31:10,088 : INFO : collected 128 word types from a corpus of 184 raw words and 3 sentences\n",
      "2019-01-27 06:31:10,089 : INFO : Loading a fresh vocabulary\n",
      "2019-01-27 06:31:10,090 : INFO : min_count=1 retains 128 unique words (100% of original 128, drops 0)\n",
      "2019-01-27 06:31:10,091 : INFO : min_count=1 leaves 184 word corpus (100% of original 184, drops 0)\n",
      "2019-01-27 06:31:10,092 : INFO : deleting the raw counts dictionary of 128 items\n",
      "2019-01-27 06:31:10,093 : INFO : sample=0.001 downsamples 128 most-common words\n",
      "2019-01-27 06:31:10,094 : INFO : downsampling leaves estimated 86 word corpus (47.1% of prior 184)\n",
      "2019-01-27 06:31:10,095 : INFO : estimated required memory for 128 words and 2 dimensions: 66048 bytes\n",
      "2019-01-27 06:31:10,096 : INFO : resetting layer weights\n",
      "2019-01-27 06:31:10,099 : INFO : training model with 2 workers on 128 vocabulary and 2 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-01-27 06:31:10,102 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-27 06:31:10,102 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-27 06:31:10,103 : INFO : EPOCH - 1 : training on 184 raw words (81 effective words) took 0.0s, 98138 effective words/s\n",
      "2019-01-27 06:31:10,103 : INFO : training on a 184 raw words (81 effective words) took 0.0s, 24203 effective words/s\n",
      "2019-01-27 06:31:10,103 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "# train_w2v.py\n",
    "\n",
    "# Input\n",
    "preprocessed_data = 'preprocessed.txt'\n",
    "\n",
    "#Knobs\n",
    "embedding_dim = 2\n",
    "\n",
    "# Output\n",
    "w2v_weights_and_word_index_mapping = 'w2v_weights_and_word_index_mapping.h5'\n",
    "\n",
    "import logging\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "logger= logging.getLogger()  # Dial\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "class W2VIter:\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "    def __iter__(self):\n",
    "        for text in self.texts:\n",
    "            yield [token for token in text.split(',') if token != '']\n",
    "\n",
    "with open(DATADIR+preprocessed_data, 'r') as f:\n",
    "    w2viter = W2VIter(f.read().split('\\n'))\n",
    "\n",
    "w2v = Word2Vec(w2viter, iter=1, min_count=1, size=embedding_dim, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['its', 'bad', 'if', 'you', 'come', 'out', 'of', 'the', 'techstars', 'program', 'without', 'any', 'funding', 'and', 'a', 'non-sustainable', 'company', 'but', 'then', 'youre', 'probably', 'screwed', 'anyways', 'vcs', 'are', 'infamously', 'inscrutable;', 'we', 'hear', 'that', 'they', 'always', 'to', 'take', 'advantage', 'naive', 'or', 'underfunded', 'companies<p>if', 'good', 'enough', 'get', 'further', 'investment', 'after', 'it', 'from', 'vc', 'already', 'know', 'instead', 'having', 'deal', 'with', 'typical', 'painful', 'negotiations', 'brad', 'felds', 'foundry', 'group', 'will', 'give', 'money', 'maybe', 'could', 'bay', 'area', 'even', 'better', 'best', 'companies', 'reinvest', 'their', 'own', 'profits', '1', 'have', 'so', 'can', 'be', 'automatically', 'logged', 'in', 'i', 'manually', 'log', 'every', 'time', 'visit', 'site', '(using', 'safari', 'here)<p>2', 'just', 'like', 'reddit', 'does', 'show', 'domain', 'each', 'link', 'belongs', 'has', 'this', 'brackets', 'headline', 'which', 'works', 'fine', 'since', 'dont', 'much', 'free', 'there', 'some', 'sites', 'sub-par', 'content', 'avoid', 'reading', 'helps', 'where', 'would', 'end', 'up', 'hover', 'over'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.vocab.keys()  # Dial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-27 06:31:10,184 : INFO : saving Word2Vec object under /home/mritter/code/twitter_nlp/sandbox_data02/myw2v.w2v, separately None\n",
      "2019-01-27 06:31:10,184 : INFO : not storing attribute vectors_norm\n",
      "2019-01-27 06:31:10,185 : INFO : not storing attribute cum_table\n",
      "2019-01-27 06:31:10,186 : INFO : saved /home/mritter/code/twitter_nlp/sandbox_data02/myw2v.w2v\n",
      "2019-01-27 06:31:10,187 : INFO : loading Word2Vec object from /home/mritter/code/twitter_nlp/sandbox_data02/myw2v.w2v\n",
      "2019-01-27 06:31:10,189 : INFO : loading wv recursively from /home/mritter/code/twitter_nlp/sandbox_data02/myw2v.w2v.wv.* with mmap=None\n",
      "2019-01-27 06:31:10,189 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-01-27 06:31:10,189 : INFO : loading vocabulary recursively from /home/mritter/code/twitter_nlp/sandbox_data02/myw2v.w2v.vocabulary.* with mmap=None\n",
      "2019-01-27 06:31:10,190 : INFO : loading trainables recursively from /home/mritter/code/twitter_nlp/sandbox_data02/myw2v.w2v.trainables.* with mmap=None\n",
      "2019-01-27 06:31:10,190 : INFO : setting ignored attribute cum_table to None\n",
      "2019-01-27 06:31:10,190 : INFO : loaded /home/mritter/code/twitter_nlp/sandbox_data02/myw2v.w2v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04180845  0.16618642]\n",
      "to the you\n",
      "Index of \"you\" is: 2\n",
      "Index of \"you\" is: 2\n"
     ]
    }
   ],
   "source": [
    "print(w2v.wv['you'][:5])\n",
    "print(w2v.wv.index2word[0], w2v.wv.index2word[1], w2v.wv.index2word[2])\n",
    "print('Index of \"you\" is: {}'.format(w2v.wv.vocab['you'].index))\n",
    "w2v.save(DATADIR+\"myw2v.w2v\")\n",
    "w2v_loaded = Word2Vec.load(DATADIR+\"myw2v.w2v\")\n",
    "print('Index of \"you\" is: {}'.format(w2v_loaded.wv.vocab['you'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 2)\n",
      "[[ 0.08827608  0.07235566]\n",
      " [ 0.16086549 -0.03138757]\n",
      " [-0.04180845  0.16618642]\n",
      " [-0.2284739   0.09721434]\n",
      " [ 0.11949734  0.12733078]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7eff67dfbba8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "l = []\n",
    "for i, token in enumerate(w2v.wv.index2word): l.append(w2v.wv[token])\n",
    "weights = np.array(l)\n",
    "print(weights.shape)\n",
    "print(weights[:5, :5])\n",
    "\n",
    "plt.scatter(weights[:, 0], weights[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(DATADIR+w2v_weights_and_word_index_mapping, \"w\") as f:\n",
    "    f.create_dataset('weights', weights.shape, dtype='f', data=weights)\n",
    "    for word in w2v.wv.vocab.keys():\n",
    "        f.create_dataset('word_to_index/{}'.format(word), (1,), dtype='int', data=w2v.wv.vocab[word].index)\n",
    "    f.create_dataset('metadata/embedding_dim', (1,), dtype='int', data=embedding_dim)\n",
    "    f.create_dataset('metadata/max_token', (1,), dtype='int', data=weights.shape[0]+1)\n",
    "    f.create_dataset('metadata/sequence_length', (1,), dtype='int', data=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(using', '1', 'a', 'advantage', 'after']\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(DATADIR+w2v_weights_and_word_index_mapping, \"r\") as f:\n",
    "    print(list(f['word_to_index'].keys())[:5])\n",
    "    print(f['word_to_index']['you'][()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28. 29. 12.  2. 30.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mritter/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# index_text.py\n",
    "\n",
    "# Input\n",
    "w2v_weights_and_word_index_mapping = 'w2v_weights_and_word_index_mapping.h5'\n",
    "preprocessed_data = 'preprocessed.txt'\n",
    "\n",
    "# Knobs\n",
    "pass\n",
    "\n",
    "# Output \n",
    "indexed_filename = 'indexed.h5'\n",
    "\n",
    "with h5py.File(DATADIR+w2v_weights_and_word_index_mapping, \"r\") as index:\n",
    "    with open(DATADIR+preprocessed_data, \"r\") as textfile:\n",
    "        \n",
    "        text_lines = textfile.read().split('\\n')\n",
    "        indexed = np.zeros(shape=(len(text_lines)-1, index['metadata']['sequence_length'].value[0]))\n",
    "        keys = index['word_to_index'].keys()\n",
    "        for line_ix, wordlist in enumerate(text_lines):\n",
    "            for word_ix, word in enumerate(wordlist.split(',')):\n",
    "                if word in keys:\n",
    "                    indexed[line_ix, word_ix] = index['word_to_index'][word][()]\n",
    "        \n",
    "    print(indexed[0, :5])  # Dial\n",
    "\n",
    "    with h5py.File(DATADIR+indexed_filename, \"w\") as f:\n",
    "        f.create_dataset('training_data', \n",
    "                         indexed.shape, \n",
    "                         dtype='int', data=indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 300, 2)            258       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300, 32)           96        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 19202     \n",
      "=================================================================\n",
      "Total params: 19,556\n",
      "Trainable params: 19,298\n",
      "Non-trainable params: 258\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model.py\n",
    "\n",
    "# Inputs\n",
    "w2v_weights_and_word_index_mapping = 'w2v_weights_and_word_index_mapping.h5'\n",
    "training_file = 'indexed.h5'\n",
    "\n",
    "# Knobs\n",
    "pass  # The whole thing, to some extent\n",
    "\n",
    "# Outputs\n",
    "compiled_model = 'compiled_model.keras'\n",
    "\n",
    "\n",
    "with h5py.File(DATADIR+w2v_weights_and_word_index_mapping, \"r\") as f:\n",
    "    embedding_matrix = f['weights'][()]\n",
    "    embedding_dim = f['metadata/embedding_dim'][0]\n",
    "    num_distinct_words = f['metadata/max_token'][0]\n",
    "    sequence_length = f['metadata/sequence_length'][0]\n",
    "    \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Embedding, Flatten\n",
    "from keras.initializers import Constant\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(sequence_length,), dtype='int32')\n",
    "\n",
    "embedded_sequences = Embedding(num_distinct_words,\n",
    "                            embedding_dim,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=sequence_length,\n",
    "                            trainable=False)(sequence_input)\n",
    "\n",
    "x = Dense(units=64, activation='relu')(embedded_sequences)\n",
    "x = Dense(units=32, activation='relu')(embedded_sequences)\n",
    "x = Flatten()(x)\n",
    "preds = Dense(units=2, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())  # Dial\n",
    "model.save(DATADIR+compiled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 0.6870 - acc: 0.5000\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6594 - acc: 1.0000\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "\n",
    "# Input\n",
    "training_file = 'indexed.h5'\n",
    "label_file = 'label_and_index.h5'\n",
    "\n",
    "# Knobs\n",
    "epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "# Output\n",
    "compiled_model = 'compiled_model.keras'\n",
    "trained_model = 'trained_model.yaml'\n",
    "trained_weights = 'trained_weights.h5'\n",
    "\n",
    "from keras.callbacks import TensorBoard as tb\n",
    "from datetime import datetime\n",
    "t = datetime.now()\n",
    "tensorboard = tb(log_dir='tensorboard_logs/{:%Y-%m-%d-%H-%M}'.format(t))  # Dial\n",
    "\n",
    "with h5py.File(DATADIR+training_file, \"r\") as f1:\n",
    "    with h5py.File(DATADIR+label_file, \"r\") as f2:\n",
    "        x_train = f1['training_data']  # Note that Keras is special in being able to read the HDF5 _object_\n",
    "        y_train = f2['training_labels']\n",
    "        \n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  shuffle='batch',  # Required for using HDF5\n",
    "                  callbacks=[tensorboard])\n",
    "\n",
    "# serialize model to YAML\n",
    "# From https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "model_yaml = model.to_yaml()\n",
    "with open(DATADIR+trained_model, \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(DATADIR+trained_weights)\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1605.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47129893"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference.py\n",
    "\n",
    "# Input\n",
    "comments_text = [\"\"\"\n",
    "Reminder, if you're in the US, the FTC says your eye doctor must give you your prescription after your exam. If a doctor refuses to do so, they can face legal action and penalties.\n",
    "\n",
    "https://www.consumer.ftc.gov/blog/2016/05/buying-prescriptio...\n",
    "\n",
    "That said, I don't think the FTC stipulates what information must appear on the prescription. Many docs leave off your PD (pupillary distance), which is a necessary measurement if you're buying online. Fortunately, there are a variety of easy ways to take this measurement yourself after the exam, although if you're really concerned about precision, you'll want the doctor's measurement.\n",
    "\n",
    "And by the way, it should go without saying, but I'll say it anyway. Although the quality of eyewear available online can be comparable to what you'd get in store ... please don't think an online eye exam is an acceptable substitute for visiting an ophthalmologist in person and getting a comprehensive eye exam! \n",
    "\"\"\"]  # This will eventually be an API call\n",
    "trained_model = 'trained_model.yaml'\n",
    "trained_weights = 'trained_weights.h5'\n",
    "w2v_weights_and_word_index_mapping = 'w2v_weights_and_word_index_mapping.h5'\n",
    "\n",
    "# Knobs\n",
    "pass\n",
    "\n",
    "# Output\n",
    "pass  # Print to command line\n",
    "\n",
    "from keras.models import model_from_yaml\n",
    "\n",
    "# load YAML and create model\n",
    "with open(DATADIR+trained_model, 'r') as yaml_file:\n",
    "    loaded_model_yaml = yaml_file.read()\n",
    "    loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(DATADIR+trained_weights)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "# preprocess (will eventually be call to same function)\n",
    "\n",
    "split_regex = r' |\\.'\n",
    "remove_regex = r\"\\'|\\\"|,|\\.|\\n|\\/|&#\\d\\d;|\\(|\\)\"\n",
    "tag_patterns = {'http.*\\w':' <LINK> '}\n",
    "positive_labels = ('pg', 'patio11', 'volida')\n",
    "sequence_length = 300\n",
    "\n",
    "pp_str = ''\n",
    "for line in tqdm.tqdm(comments_text):  # Dial\n",
    "    temp_text = line\n",
    "    temp_text = temp_text.lower()\n",
    "    for key, value in tag_patterns.items():\n",
    "        temp_text = re.sub(key, value, temp_text)\n",
    "    text = re.split(split_regex, re.sub(remove_regex, '', temp_text))\n",
    "    print(len(text))\n",
    "    text += ['']*(sequence_length-len(text))\n",
    "    text += ['\\n']\n",
    "    pp_str += ','.join(text)\n",
    "\n",
    "    \n",
    "    \n",
    "with h5py.File(DATADIR+w2v_weights_and_word_index_mapping, \"r\") as index:       \n",
    "    text_lines = pp_str.split('\\n')\n",
    "    indexed = np.zeros(shape=(len(text_lines)-1, index['metadata']['sequence_length'][0]))\n",
    "    keys = index['word_to_index'].keys()\n",
    "    for line_ix, wordlist in enumerate(text_lines):\n",
    "        for word_ix, word in enumerate(wordlist.split(',')):\n",
    "            if word in keys:\n",
    "                indexed[line_ix, word_ix] = index['word_to_index'][word][()]\n",
    "    \n",
    "loaded_model.predict(indexed)[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 11466.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "36\n",
      "11\n",
      "[[0.47292626 0.5270738 ]\n",
      " [0.47406328 0.5259367 ]\n",
      " [0.4730903  0.5269097 ]]\n",
      "['phil', 'volida', 'volida']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test.py\n",
    "\n",
    "# Call all the same \n",
    "\n",
    "test_filename = 'downloaded_test'\n",
    "trained_model = 'trained_model'\n",
    "\n",
    "# Input\n",
    "raw_data = 'raw_data_test.jsonl'\n",
    "\n",
    "# Knobs\n",
    "status = 'training'\n",
    "filter_bool = ('type', 'comment') \n",
    "split_regex = r' |\\.'\n",
    "remove_regex = r\"\\'|\\\"|,|\\.|\\n|\\/|&#\\d\\d;|\\(|\\)\"\n",
    "tag_patterns = {'http.*\\w':' <LINK> '}\n",
    "positive_labels = ('pg', 'patio11', 'volida')\n",
    "sequence_length = 300\n",
    "\n",
    "# Output\n",
    "pass  # Print\n",
    "\n",
    "actual_labels = []\n",
    "original_ids = []\n",
    "outfile_text = ''\n",
    "\n",
    "with open(DATADIR+raw_data, 'r') as infile:\n",
    "    with open(DATADIR+preprocessed_data, 'w') as outfile:\n",
    "        for line in tqdm.tqdm(infile):  # Dial\n",
    "            line_json = json.loads(line)\n",
    "\n",
    "            if line_json[filter_bool[0]] != filter_bool[1]: continue\n",
    "            temp_text = line_json['text']\n",
    "            temp_text = temp_text.lower()\n",
    "            for key, value in tag_patterns.items():\n",
    "                temp_text = re.sub(key, value, temp_text)\n",
    "            text = re.split(split_regex, re.sub(remove_regex, '', temp_text))\n",
    "            print(len(text))\n",
    "            text += ['']*(sequence_length-len(text))\n",
    "            text += ['\\n']\n",
    "            outfile_text += ','.join(text)\n",
    "            \n",
    "            actual_labels.append(line_json['by'])\n",
    "            \n",
    "            \n",
    "with h5py.File(DATADIR+w2v_weights_and_word_index_mapping, \"r\") as index:       \n",
    "    text_lines = outfile_text.split('\\n')\n",
    "    sequence_length = index['metadata']['sequence_length'][0]\n",
    "    indexed = np.zeros(shape=(len(text_lines)-1, sequence_length))\n",
    "    keys = index['word_to_index'].keys()\n",
    "    for line_ix, wordlist in enumerate(text_lines):\n",
    "        for word_ix, word in enumerate(wordlist.split(',')[:sequence_length]):\n",
    "            if word in keys:\n",
    "                indexed[line_ix, word_ix] = index['word_to_index'][word][()]\n",
    "    \n",
    "print(loaded_model.predict(indexed))\n",
    "print(actual_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
