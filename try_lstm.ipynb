{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mritter/anaconda3/envs/tf_gpu_test04/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/mritter/anaconda3/envs/tf_gpu_test04:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "tensorflow-gpu            1.5.0                         0  \r\n",
      "tensorflow-gpu-base       1.5.0            py36h8a131e3_0  \r\n"
     ]
    }
   ],
   "source": [
    "! conda list tensorflow-gpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-209078942ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# confirm TensorFlow sees the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m'GPU'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# confirm Keras sees the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/tensorflow/python/client/device_lib.py\u001b[0m in \u001b[0;36mlist_local_devices\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mlist_devices\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mListDevices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu_test04/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "# IF IT DOES NOT WORK, MAY NEED TO RESTART COMPUTER\n",
    "\n",
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "assert len(backend.tensorflow_backend._get_available_gpus()) > 0\n",
    "\n",
    "# confirm PyTorch sees the GPU\n",
    "from torch import cuda\n",
    "assert cuda.is_available()\n",
    "assert cuda.device_count() > 0\n",
    "print(cuda.get_device_name(cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "with h5py.File('data/padded_data.h5','r') as h5f:\n",
    "    data = h5f['dataset_1'][:]\n",
    "with h5py.File('data/labels.h5','r') as h5f:\n",
    "    labels = h5f['dataset_1'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   1,   5,  14],\n",
       "       [  0,   0,   0, ...,  44,   2,  14],\n",
       "       [  0,   0,   0, ...,   7,  14,  15],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  20,  14,   1],\n",
       "       [  0,   0,   0, ..., 284, 186,   8],\n",
       "       [  0,   0,   0, ...,   3,  76,  64]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n",
      "CPU times: user 8.26 s, sys: 196 ms, total: 8.46 s\n",
      "Wall time: 8.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This is actually super fast\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "import os \n",
    "BASE_DIR = '/home/mritter/code/twitter_nlp/newsgroups_data/'\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove')\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# prepare embedding matrix\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "num_distinct_words = len(tokenizer.word_index) + 1  # For <UNKNOWN> \n",
    "EMBEDDING_DIM = 100  # Dimensions to represent each token\n",
    "\n",
    "embedding_matrix = np.zeros((num_distinct_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > num_distinct_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Closed HDF5 file>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "with h5py.File('data/whole_data.h5', 'r') as h5f:\n",
    "    embedding_matrix = h5f['embedding_matrix'][:]\n",
    "    xtrain = h5f['x_train'][:]\n",
    "    ytrain = h5f['y_train'][:]\n",
    "    x_val = h5f['x_val'][:]\n",
    "    y_val = h5f['y_val'][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57664, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47578, 500)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "\n",
    "num_distinct_words, EMBEDDING_DIM = embedding_matrix.shape\n",
    "embedding_layer = Embedding(num_distinct_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=xtrain.shape[1],\n",
    "                            trainable=False)\n",
    "\n",
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(xtrain.shape[1],), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "x = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(embedded_sequences)\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "# x = MaxPooling1D(5)(x)\n",
    "# x = Conv1D(128, 5, activation='relu')(x)\n",
    "# x = MaxPooling1D(5)(x)\n",
    "# x = Conv1D(128, 5, activation='relu')(x)\n",
    "# x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "preds = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 500, 100)          5766400   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,908,546\n",
      "Trainable params: 142,146\n",
      "Non-trainable params: 5,766,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# K.clear_session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47578 samples, validate on 11894 samples\n",
      "Epoch 1/10\n",
      "47578/47578 [==============================] - 420s 9ms/step - loss: 0.3567 - acc: 0.8599 - val_loss: 0.3421 - val_acc: 0.8741\n",
      "Epoch 2/10\n",
      "47578/47578 [==============================] - 433s 9ms/step - loss: 0.2821 - acc: 0.8920 - val_loss: 0.2706 - val_acc: 0.8999\n",
      "Epoch 3/10\n",
      "47578/47578 [==============================] - 426s 9ms/step - loss: 0.2588 - acc: 0.9045 - val_loss: 0.2694 - val_acc: 0.9011\n",
      "Epoch 4/10\n",
      "47578/47578 [==============================] - 429s 9ms/step - loss: 0.2442 - acc: 0.9099 - val_loss: 0.2430 - val_acc: 0.9114\n",
      "Epoch 5/10\n",
      "47578/47578 [==============================] - 417s 9ms/step - loss: 0.2334 - acc: 0.9149 - val_loss: 0.2382 - val_acc: 0.9126\n",
      "Epoch 6/10\n",
      "47578/47578 [==============================] - 413s 9ms/step - loss: 0.2250 - acc: 0.9182 - val_loss: 0.2424 - val_acc: 0.9141\n",
      "Epoch 7/10\n",
      "47578/47578 [==============================] - 413s 9ms/step - loss: 0.2190 - acc: 0.9204 - val_loss: 0.2270 - val_acc: 0.9179\n",
      "Epoch 8/10\n",
      "47578/47578 [==============================] - 410s 9ms/step - loss: 0.2120 - acc: 0.9239 - val_loss: 0.2380 - val_acc: 0.9137\n",
      "Epoch 9/10\n",
      "47578/47578 [==============================] - 411s 9ms/step - loss: 0.2084 - acc: 0.9242 - val_loss: 0.2408 - val_acc: 0.9135\n",
      "Epoch 10/10\n",
      "32448/47578 [===================>..........] - ETA: 2:01 - loss: 0.1990 - acc: 0.9288"
     ]
    }
   ],
   "source": [
    "# Create a TensorBoard instance with the path to the logs directory\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard as tb\n",
    "from datetime import datetime\n",
    "t = datetime.now()\n",
    "tensorboard = tb(log_dir='tensorboard_logs/{:%Y-%m-%d-%H-%M}'.format(t))\n",
    "\n",
    "model.fit(xtrain, ytrain,\n",
    "          batch_size=64, #128,\n",
    "          epochs=10,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
